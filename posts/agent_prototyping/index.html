<!doctype html><html lang=en dir=auto><head><meta name=description content="Two approaches to building agentic experiences: platform-first vs scenario-first. How AI coding tools enable faster prototyping and cross-functional collaboration for agent product development."><meta name=keywords content="AI agents,product development,prototyping,AI coding tools,agent frameworks,product-market fit,cross-functional collaboration,scenario design"><meta name=author content="Terry Chen"><meta name=robots content="index, follow"><meta name=language content="en-us"><meta name=revisit-after content="7 days"><meta name=distribution content="global"><meta name=rating content="general"><link rel=canonical href=https://chenterry.com/posts/agent_prototyping/><meta property="og:title" content="Iterating at the Pace of AI | Terry Chen"><meta property="og:description" content="Two approaches to building agentic experiences: platform-first vs scenario-first. How AI coding tools enable faster prototyping and cross-functional collaboration for agent product development."><meta property="og:type" content="article"><meta property="og:url" content="https://chenterry.com/posts/agent_prototyping/"><meta property="og:site_name" content="Terry Chen"><meta property="og:locale" content="en-us"><meta property="article:published_time" content="2025-08-29T00:00:00Z"><meta property="article:modified_time" content="2025-08-29T00:00:00Z"><meta property="article:author" content="Terry Chen"><meta property="article:tag" content="Product"><meta property="og:image" content="https://chenterry.com/images/profile.jpg"><meta property="og:image:width" content="1200"><meta property="og:image:height" content="630"><meta property="og:image:alt" content="Terry Chen"><meta name=twitter:card content="summary_large_image"><meta name=twitter:site content="@terrychen_ai"><meta name=twitter:creator content="@terrychen_ai"><meta name=twitter:title content="Iterating at the Pace of AI | Terry Chen"><meta name=twitter:description content="Two approaches to building agentic experiences: platform-first vs scenario-first. How AI coding tools enable faster prototyping and cross-functional collaboration for agent product development."><meta name=twitter:image content="https://chenterry.com/images/profile.jpg"><meta name=twitter:image:alt content="Terry Chen"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Iterating at the Pace of AI","datePublished":"2025-08-29T00:00:00Z","dateModified":"2025-08-29T00:00:00Z","author":{"@type":"Person","name":"Terry Chen","url":"https:\/\/chenterry.com\/"},"publisher":{"@type":"Organization","name":"Terry Chen","logo":{"@type":"ImageObject","url":"https:\/\/chenterry.com\/images/profile.jpg"}},"description":"Two approaches to building agentic experiences: platform-first vs scenario-first. How AI coding tools enable faster prototyping and cross-functional collaboration for agent product development.","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/chenterry.com\/posts\/agent_prototyping\/"},"keywords":"AI agents, product development, prototyping, AI coding tools, agent frameworks, product-market fit, cross-functional collaboration, scenario design","articleSection":"posts","image":{"@type":"ImageObject","url":"https:\/\/chenterry.com\/images\/profile.jpg","width":1200,"height":630}}</script><meta name=article:published_time content="2025-08-29T00:00:00Z"><meta name=article:modified_time content="2025-08-29T00:00:00Z"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//www.google-analytics.com><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Iterating at the Pace of AI | Terry Chen</title>
<meta name=keywords content="AI agents,product development,prototyping,AI coding tools,agent frameworks,product-market fit,cross-functional collaboration,scenario design"><meta name=author content="Terry Chen"><link rel=canonical href=https://chenterry.com/posts/agent_prototyping/><link crossorigin=anonymous href=/assets/css/stylesheet.f495fe1dedb119b2969e64d021ab84ebb9f24a5086308bd0222ece1b182e151e.css integrity="sha256-9JX+He2xGbKWnmTQIauE67nySlCGMIvQIi7OGxguFR4=" rel="preload stylesheet" as=style><link rel=icon href=https://chenterry.com/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://chenterry.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://chenterry.com/favicon-32x32.png><link rel=apple-touch-icon href=https://chenterry.com/apple-touch-icon.png><link rel=mask-icon href=https://chenterry.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=manifest href=https://chenterry.com/manifest.json><link rel=alternate hreflang=en href=https://chenterry.com/posts/agent_prototyping/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=icon href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üòú</text></svg>" type=image/svg+xml><link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üòú</text></svg>"><script async src="https://www.googletagmanager.com/gtag/js?id=G-M6GS8Q702L"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-M6GS8Q702L")}</script><meta property="og:url" content="https://chenterry.com/posts/agent_prototyping/"><meta property="og:site_name" content="Terry Chen"><meta property="og:title" content="Iterating at the Pace of AI"><meta property="og:description" content="Two approaches to building agentic experiences: platform-first vs scenario-first. How AI coding tools enable faster prototyping and cross-functional collaboration for agent product development."><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-08-29T00:00:00+00:00"><meta property="article:modified_time" content="2025-08-29T00:00:00+00:00"><meta property="article:tag" content="Product"><meta property="og:image" content="https://chenterry.com/images/profile.jpg"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://chenterry.com/images/profile.jpg"><meta name=twitter:title content="Iterating at the Pace of AI"><meta name=twitter:description content="Two approaches to building agentic experiences: platform-first vs scenario-first. How AI coding tools enable faster prototyping and cross-functional collaboration for agent product development."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://chenterry.com/posts/"},{"@type":"ListItem","position":2,"name":"Iterating at the Pace of AI","item":"https://chenterry.com/posts/agent_prototyping/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Iterating at the Pace of AI","name":"Iterating at the Pace of AI","description":"Two approaches to building agentic experiences: platform-first vs scenario-first. How AI coding tools enable faster prototyping and cross-functional collaboration for agent product development.","keywords":["AI agents","product development","prototyping","AI coding tools","agent frameworks","product-market fit","cross-functional collaboration","scenario design"],"articleBody":"There are two credible paths to building agentic experiences. The first is platform-first: stand up a unified agent framework with the core capabilities‚Äîmulti-turn conversation, a knowledge base, and memory‚Äîand then layer in signifiers and affordances that fit your environment. The second is scenario-first: begin with the thinnest viable surface and add only the features that demonstrably create value beyond what ChatGPT or Copilot already provide, bringing in memory and other ‚Äúplatform‚Äù features only once they have earned their keep. The platform-first approach yields a consistent engineering experience and lets teams reuse prior agent work, but it risks poor agent‚Äìscenario fit. The scenario-first approach can feel messier and demands more from product managers, yet it validates real-world use cases faster. I don‚Äôt claim one approach is universally better‚Äîstartups and large companies face different constraints‚Äîbut I do believe there is only one way to prototype: ship quickly, test explicit hypotheses, and iterate without delay.\nA clarifying question keeps this cadence honest: what is the minimum version of the product that lets us learn whether the solution can find product‚Äìmarket fit? Counterintuitively, you often do not need a working prototype to answer that. Walking through end-to-end customer scenarios frequently reveals whether a proposed feature fits existing workflows and where it will break. That said, some questions hinge on new engineering‚Äîexperiences that are hard to reason about in the abstract. In those cases, the objective is not to ‚Äúbuild the demo,‚Äù but to surface and test the assumptions that matter. Each design choice should map to the outcome it seeks and to the user challenge it addresses. The simpler the stack, the more learning cycles you can run with less effort, which is the real engine of progress.\nModern AI coding tools make this possible. Cursor, GitHub Copilot, and Claude Code compress build time by generating boilerplate, suggesting common patterns, and helping troubleshoot. A single engineer can now produce a functional MVP in a fraction of the time that used to require a small team. Much like Figma tightened the collaboration loop in design, these tools narrow the gap between product intent and implementation. The result is not merely faster engineering; it is broader participation. Product managers, designers, even sales and customer success teams can test ideas more directly, while engineers concentrate on production-grade systems and reliability concerns that truly benefit from their specialization.\nInvolving Cross-Functional Stakeholders An agentic experience is only as good as our understanding of the underlying problem. This is especially true for expert workflows‚Äîconsumption-based cost estimation or SOC investigation, for example‚Äîwhere product and engineering teams are rarely the domain experts. Involving architects, sales engineers, and analysts only at the prompt-iteration stage is not enough. To build agent behaviors that actually fit, we have to internalize existing workflows and best practices, then design signifiers and affordances that match practitioner expectations. Language, steps, intermediate outputs, and handoffs should mirror how experts already think and work. When the agent speaks their dialect and respects their process, adoption follows because the experience feels native rather than novel for novelty‚Äôs sake.\nThis is exactly where the Figma analogy‚ÄîKevin Kwok‚Äôs point about non-linear returns from tighter collaboration loops‚Äîbecomes operational. Figma did not just make drawing easier; it made critique, alignment, and decision-making happen in the same place, by the right people, at the right time. AI coding assistants catalyze a similar shift for agentic products: they collapse the distance between a domain expert‚Äôs intent and a working prototype, making assumptions explicit, turning tacit heuristics into checkable rules, and surfacing disagreements while they are still cheap to resolve. When prototypes function as shared canvases‚Äîco-edited by PMs, engineers, and subject-matter experts‚Äîthe loop tightens further: experts shape the signifiers and workflows, product sharpens the hypotheses, and engineering focuses on robustness and safety. The compounding return comes not from adding more features, but from aligning agent behavior with the realities of the domain.\nLearnings from the Cost Estimator Agent To ground these principles, let‚Äôs look at an agentic implementation of a cost estimation scenario\nProject Context Customers need accurate cost estimates for budget planning and solution comparison, yet consumption-based pricing is notoriously hard to predict. We heard repeatedly from the field that this uncertainty stalls decisions and, in competitive deals, can tilt outcomes against us. Existing tools do not help enough. Web calculators feel like black boxes with coarse, inflexible inputs and little transparency. Spreadsheet models are opaque and fragile, with assumptions scattered across cells. Both often ask for inputs customers do not understand or cannot provide without heavy translation.\nIn other words, this is not a known unknowns problem where a general-purpose copilot can retrieve an answer upon request. Nor is it an unknown knowns problem where the customer already has a tried-and-true estimation method and we simply need to automate it. It is often an unknown unknowns problem: customers do not know what to ask, and they do not have the raw data in the needed form. The result is planning paralysis and, ultimately, stalled or lost deals.\nDesign Rationale Designing for ‚Äúunknown unknowns‚Äù required optimizing along three intertwined dimensions. First, we focused on transparency and control so that users could see the reasoning behind estimates‚Äîthe assumptions, intermediate calculations, and trade-offs‚Äîand adjust inputs with confidence. Numbers without narrative do not build trust, and trust is the currency of estimation. Second, we embedded domain expertise directly in the experience. Instead of pushing the knowledge gap back to the user, the system translated familiar facts‚Äîindustry patterns, ingestion profiles, retention policies‚Äîinto the metrics the pricing model requires, pre-populating where possible and teaching as it went. Third, we treated estimation as a process rather than a form, and we designed for iterative refinement. The goal was not a one-shot answer but a guided conversation that converges on confidence.\nAt a basic level, we began with an agent side-panel, similar to a Copilot, to unify product documentation, pricing schemas, and frequently asked questions. This supported conversational guidance throughout the estimation process, but it also exposed three frictions we had to solve in order to achieve fit. First, use-case discovery was weak: without strong signifiers, users did not know what to ask and often ventured beyond the agent‚Äôs scope. Second, chat lacked context: humans are economical with effort, so expecting users to restate all the fields they had filled and the stage they were in created unnecessary friction. Third, people don‚Äôt know what they don‚Äôt know: there is a structural gap between what customers know about their business (for example, number of users, typical event patterns) and what we require to estimate costs (for example, daily gigabytes ingested). Simply asking, ‚ÄúHow many gigabytes per day?‚Äù does not bridge that gap.\nFigure 6: The default pricing panel\nFigure 7: Adding an agent side bar\nThese insights shaped a prototype with two synchronized surfaces: a pricing panel and an agent panel kept in bidirectional sync. Edits in the graphical interface updated the conversation‚Äôs context, and the agent‚Äôs reasoning flowed back as explanation cards anchored beside the fields they affected.\nIn brownfield scenarios, the agent could pull relevant account signals to prefill inputs and explain each value‚Äôs provenance. In greenfield scenarios, the experience offered size recommendations‚Äîsmall, medium, large, enterprise‚Äîthat users could apply with one click, each accompanied by clear rationales and editable assumptions.\nWhen hard numbers were missing‚Äîsay, daily ingestion in gigabytes‚Äîthe agent asked questions users could answer about environment size, event rates, and retention needs, then converted those responses into derived estimates, showing the math and inviting adjustments. Under the hood, a focused knowledge base provided product and pricing facts, while three structured workflows‚Äîvolume estimation, pricing estimation, and design recommendations‚Äîgave the conversation shape and kept it oriented toward decisions rather than dialogue for its own sake.\nFigure 8: Bi-directional Sync, Agent Cards\nFigure 9: Explanation Cards\nEvaluation and Benchmarking Agent platforms encourage generality, but effectiveness must be demonstrated on concrete tasks. We evaluate the experience by asking whether it completes representative estimation scenarios end to end, how its outputs compare to human-expert baselines, and how quickly it converges to a result stakeholders trust. Accuracy matters, but so do user effort and confidence. When building agentic experiences, we should track time to an acceptable estimate, the number of clarifying turns, and whether users report understanding and accepting the assumptions they carry forward. Scenario coverage also matters: behavior needs to hold not only in the ‚Äúhappy path,‚Äù but across brownfield and greenfield cases, high-volume and bursty workloads, and strict-retention and cost-optimized policies. When behavior degrades, it should degrade gracefully with clear explanations, ranges, or a handoff to a human expert. In larger organizations, evaluation pairs with safeguards. Data validation and drift monitoring ensure that quotes reflect current pricing and product information, with alerts when underlying references change. Guardrails protect embedded expert logic‚Äîestimation methods and pricing strategies‚Äîagainst prompt injection and leakage of system instructions, and they constrain access to sensitive APIs. Finally, bad-case handling is a first-class requirement: the system detects ambiguous inputs, surfaces low-confidence steps, and offers conservative defaults or escalation paths rather than silently producing spurious precision. Specifications and engineering plans that omit scenario walkthroughs, benchmarks, and safeguards drift toward imagined use cases and weak agent‚Äìscenario fit; those that include them turn agentic ambition into reliable impact.\nClosing Thoughts Choose a build path that fits your context, but always prototype to learn, not to impress. Use AI tools to shorten the distance between ideas and feedback. Bring domain experts into the design of signifiers and workflows so the agent respects reality. Make reasoning visible, embed expertise at the point of need, and shape the experience for iterative refinement. Then prove it with scenario-based evaluation and strong guardrails. This, I believe, is how you truly iterate at the pace of AI.\n","wordCount":"1613","inLanguage":"en","image":"https://chenterry.com/images/profile.jpg","datePublished":"2025-08-29T00:00:00Z","dateModified":"2025-08-29T00:00:00Z","author":{"@type":"Person","name":"Terry Chen"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://chenterry.com/posts/agent_prototyping/"},"publisher":{"@type":"Organization","name":"Terry Chen","logo":{"@type":"ImageObject","url":"https://chenterry.com/favicon.ico"}}}</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-M6GS8Q702L"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","MEASUREMENT_ID")</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Iterating at the Pace of AI","image":"https:\/\/chenterry.com\/","datePublished":"2025-08-29T00:00:00\u002b00:00","dateModified":"2025-08-29T00:00:00\u002b00:00","author":{"@type":"Person","name":"Terry Chen"},"publisher":{"@type":"Organization","name":"Terry Chen","logo":{"@type":"ImageObject","url":"https:\/\/chenterry.com\/"}},"description":"Two approaches to building agentic experiences: platform-first vs scenario-first. How AI coding tools enable faster prototyping and cross-functional collaboration for agent product development.","keywords":["AI agents","product development","prototyping","AI coding tools","agent frameworks","product-market fit","cross-functional collaboration","scenario design"],"wordCount":"1613","timeRequired":"PT8M"}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https:\/\/chenterry.com\/"},{"@type":"ListItem","position":2,"name":"Posts","item":"https:\/\/chenterry.com\/posts/"},{"@type":"ListItem","position":3,"name":"Iterating at the Pace of AI","item":"https:\/\/chenterry.com\/posts\/agent_prototyping\/"}]}</script><style>link[rel=icon]{content:url("data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üòú</text></svg>")}</style></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://chenterry.com/ accesskey=h title="Terry Chen (Alt + H)">Terry Chen</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=/posts/ title=Posts><span class=active>Posts</span></a></li><li><a href=/product/ title=Product><span>Product</span></a></li><li><a href=/investing/ title=Investing><span>Investing</span></a></li><li><a href=/search/ title=Explore accesskey=/><span>Explore</span></a></li><li><a href=/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Iterating at the Pace of AI</h1><div class=post-meta>By Terry Chen ‚Ä¢
<time>August 29, 2025</time></div></header><div class=post-content><p>There are two credible paths to building agentic experiences. The first is platform-first: stand up a unified agent framework with the core capabilities‚Äîmulti-turn conversation, a knowledge base, and memory‚Äîand then layer in signifiers and affordances that fit your environment. The second is scenario-first: begin with the thinnest viable surface and add only the features that demonstrably create value beyond what ChatGPT or Copilot already provide, bringing in memory and other ‚Äúplatform‚Äù features only once they have earned their keep. The platform-first approach yields a consistent engineering experience and lets teams reuse prior agent work, but it risks poor agent‚Äìscenario fit. The scenario-first approach can feel messier and demands more from product managers, yet it validates real-world use cases faster. I don‚Äôt claim one approach is universally better‚Äîstartups and large companies face different constraints‚Äîbut I do believe there is only one way to prototype: ship quickly, test explicit hypotheses, and iterate without delay.</p><p><img src=/images/posts/agent_prototyping/figure1.png alt="Figure 1: Cost Estimator Agent Prototype" loading=lazy>
A clarifying question keeps this cadence honest: what is the minimum version of the product that lets us learn whether the solution can find product‚Äìmarket fit? Counterintuitively, you often do not need a working prototype to answer that. Walking through end-to-end customer scenarios frequently reveals whether a proposed feature fits existing workflows and where it will break. That said, some questions hinge on new engineering‚Äîexperiences that are hard to reason about in the abstract. In those cases, the objective is not to &ldquo;build the demo,&rdquo; but to surface and test the assumptions that matter. Each design choice should map to the outcome it seeks and to the user challenge it addresses. The simpler the stack, the more learning cycles you can run with less effort, which is the real engine of progress.</p><p><img src=/images/posts/agent_prototyping/figure2.png alt="Figure 2: Value adds of &ldquo;vibe coding&rdquo; tools" loading=lazy>
Modern AI coding tools make this possible. Cursor, GitHub Copilot, and Claude Code compress build time by generating boilerplate, suggesting common patterns, and helping troubleshoot. A single engineer can now produce a functional MVP in a fraction of the time that used to require a small team. Much like Figma tightened the collaboration loop in design, these tools narrow the gap between product intent and implementation. The result is not merely faster engineering; it is broader participation. Product managers, designers, even sales and customer success teams can test ideas more directly, while engineers concentrate on production-grade systems and reliability concerns that truly benefit from their specialization.</p><h2 id=involving-cross-functional-stakeholders>Involving Cross-Functional Stakeholders</h2><p>An agentic experience is only as good as our understanding of the underlying problem. This is especially true for expert workflows‚Äîconsumption-based cost estimation or SOC investigation, for example‚Äîwhere product and engineering teams are rarely the domain experts. Involving architects, sales engineers, and analysts only at the prompt-iteration stage is not enough. To build agent behaviors that actually fit, we have to internalize existing workflows and best practices, then design signifiers and affordances that match practitioner expectations. Language, steps, intermediate outputs, and handoffs should mirror how experts already think and work. When the agent speaks their dialect and respects their process, adoption follows because the experience feels native rather than novel for novelty‚Äôs sake.</p><p><img src=/images/posts/agent_prototyping/figure3.png alt="Figure 3: Collaboration workflows enabled by Figma, Credit to Kevin Kwok" loading=lazy></p><p>This is exactly where the Figma analogy‚ÄîKevin Kwok‚Äôs point about non-linear returns from tighter collaboration loops‚Äîbecomes operational. Figma did not just make drawing easier; it made critique, alignment, and decision-making happen in the same place, by the right people, at the right time. AI coding assistants catalyze a similar shift for agentic products: they collapse the distance between a domain expert‚Äôs intent and a working prototype, making assumptions explicit, turning tacit heuristics into checkable rules, and surfacing disagreements while they are still cheap to resolve. When prototypes function as shared canvases‚Äîco-edited by PMs, engineers, and subject-matter experts‚Äîthe loop tightens further: experts shape the signifiers and workflows, product sharpens the hypotheses, and engineering focuses on robustness and safety. The compounding return comes not from adding more features, but from aligning agent behavior with the realities of the domain.</p><h2 id=learnings-from-the-cost-estimator-agent>Learnings from the Cost Estimator Agent</h2><p>To ground these principles, let&rsquo;s look at an agentic implementation of a cost estimation scenario</p><p><img src=/images/posts/agent_prototyping/figure4.png alt="Figure 4: Integrated web UX with agent workflows" loading=lazy></p><h3 id=project-context>Project Context</h3><p>Customers need accurate cost estimates for budget planning and solution comparison, yet consumption-based pricing is notoriously hard to predict. We heard repeatedly from the field that this uncertainty stalls decisions and, in competitive deals, can tilt outcomes against us. Existing tools do not help enough. Web calculators feel like black boxes with coarse, inflexible inputs and little transparency. Spreadsheet models are opaque and fragile, with assumptions scattered across cells. Both often ask for inputs customers do not understand or cannot provide without heavy translation.</p><p>In other words, this is not a known unknowns problem where a general-purpose copilot can retrieve an answer upon request. Nor is it an unknown knowns problem where the customer already has a tried-and-true estimation method and we simply need to automate it. It is often an unknown unknowns problem: customers do not know what to ask, and they do not have the raw data in the needed form. The result is planning paralysis and, ultimately, stalled or lost deals.</p><p><img src=/images/posts/agent_prototyping/figure5.png alt="Figure 5: The Knowledge Quadrant mapping agent scenarios" loading=lazy></p><h3 id=design-rationale>Design Rationale</h3><p>Designing for ‚Äúunknown unknowns‚Äù required optimizing along three intertwined dimensions. First, we focused on transparency and control so that users could see the reasoning behind estimates‚Äîthe assumptions, intermediate calculations, and trade-offs‚Äîand adjust inputs with confidence. Numbers without narrative do not build trust, and trust is the currency of estimation. Second, we embedded domain expertise directly in the experience. Instead of pushing the knowledge gap back to the user, the system translated familiar facts‚Äîindustry patterns, ingestion profiles, retention policies‚Äîinto the metrics the pricing model requires, pre-populating where possible and teaching as it went. Third, we treated estimation as a process rather than a form, and we designed for iterative refinement. The goal was not a one-shot answer but a guided conversation that converges on confidence.</p><p>At a basic level, we began with an agent side-panel, similar to a Copilot, to unify product documentation, pricing schemas, and frequently asked questions. This supported conversational guidance throughout the estimation process, but it also exposed three frictions we had to solve in order to achieve fit. First, use-case discovery was weak: without strong signifiers, users did not know what to ask and often ventured beyond the agent‚Äôs scope. Second, chat lacked context: humans are economical with effort, so expecting users to restate all the fields they had filled and the stage they were in created unnecessary friction. Third, people don‚Äôt know what they don‚Äôt know: there is a structural gap between what customers know about their business (for example, number of users, typical event patterns) and what we require to estimate costs (for example, daily gigabytes ingested). Simply asking, ‚ÄúHow many gigabytes per day?‚Äù does not bridge that gap.</p><div style="display:flex;gap:20px;margin:20px 0"><div style=flex:1><img src=/images/posts/agent_prototyping/figure6.png alt="Figure 6: The default pricing panel" style=width:100%><p style=text-align:center;font-style:italic;margin-top:10px>Figure 6: The default pricing panel</p></div><div style=flex:1><img src=/images/posts/agent_prototyping/figure7.png alt="Figure 7: Adding an agent side bar" style=width:100%><p style=text-align:center;font-style:italic;margin-top:10px>Figure 7: Adding an agent side bar</p></div></div><p>These insights shaped a prototype with two synchronized surfaces: a pricing panel and an agent panel kept in bidirectional sync. Edits in the graphical interface updated the conversation‚Äôs context, and the agent‚Äôs reasoning flowed back as explanation cards anchored beside the fields they affected.</p><p>In brownfield scenarios, the agent could pull relevant account signals to prefill inputs and explain each value‚Äôs provenance. In greenfield scenarios, the experience offered size recommendations‚Äîsmall, medium, large, enterprise‚Äîthat users could apply with one click, each accompanied by clear rationales and editable assumptions.</p><p>When hard numbers were missing‚Äîsay, daily ingestion in gigabytes‚Äîthe agent asked questions users could answer about environment size, event rates, and retention needs, then converted those responses into derived estimates, showing the math and inviting adjustments. Under the hood, a focused knowledge base provided product and pricing facts, while three structured workflows‚Äîvolume estimation, pricing estimation, and design recommendations‚Äîgave the conversation shape and kept it oriented toward decisions rather than dialogue for its own sake.</p><div style="display:flex;gap:20px;margin:20px 0"><div style=flex:1><img src=/images/posts/agent_prototyping/figure8.png alt="Figure 8: Bi-directional Sync, Agent Cards" style=width:100%><p style=text-align:center;font-style:italic;margin-top:10px>Figure 8: Bi-directional Sync, Agent Cards</p></div><div style=flex:1><img src=/images/posts/agent_prototyping/figure9.png alt="Figure 9: Explanation Cards" style=width:100%><p style=text-align:center;font-style:italic;margin-top:10px>Figure 9: Explanation Cards</p></div></div><h2 id=evaluation-and-benchmarking>Evaluation and Benchmarking</h2><p>Agent platforms encourage generality, but effectiveness must be demonstrated on concrete tasks. We evaluate the experience by asking whether it completes representative estimation scenarios end to end, how its outputs compare to human-expert baselines, and how quickly it converges to a result stakeholders trust. Accuracy matters, but so do user effort and confidence. When building agentic experiences, we should track time to an acceptable estimate, the number of clarifying turns, and whether users report understanding and accepting the assumptions they carry forward. Scenario coverage also matters: behavior needs to hold not only in the ‚Äúhappy path,‚Äù but across brownfield and greenfield cases, high-volume and bursty workloads, and strict-retention and cost-optimized policies. When behavior degrades, it should degrade gracefully with clear explanations, ranges, or a handoff to a human expert.
In larger organizations, evaluation pairs with safeguards. Data validation and drift monitoring ensure that quotes reflect current pricing and product information, with alerts when underlying references change. Guardrails protect embedded expert logic‚Äîestimation methods and pricing strategies‚Äîagainst prompt injection and leakage of system instructions, and they constrain access to sensitive APIs. Finally, bad-case handling is a first-class requirement: the system detects ambiguous inputs, surfaces low-confidence steps, and offers conservative defaults or escalation paths rather than silently producing spurious precision. Specifications and engineering plans that omit scenario walkthroughs, benchmarks, and safeguards drift toward imagined use cases and weak agent‚Äìscenario fit; those that include them turn agentic ambition into reliable impact.</p><h2 id=closing-thoughts>Closing Thoughts</h2><p>Choose a build path that fits your context, but always prototype to learn, not to impress. Use AI tools to shorten the distance between ideas and feedback. Bring domain experts into the design of signifiers and workflows so the agent respects reality. Make reasoning visible, embed expertise at the point of need, and shape the experience for iterative refinement. Then prove it with scenario-based evaluation and strong guardrails. This, I believe, is how you truly iterate at the pace of AI.</p></div><footer class=post-footer><div class=post-tags><a href=/tags/product>Product</a></div></footer></article><div class=related-posts><h3>Related Articles</h3><div class=related-posts-grid><a href=/posts/need_validation/ class=related-post-card><div class=related-post-content><h4>Social Listening for Product Insight</h4><div class=related-post-meta><span class=related-post-date>August 29, 2025</span>
<span class=related-post-tags>#Product</span></div><p class=related-post-excerpt>Why We Need More Ways to Hear Customers As product teams scale, direct exposure to customers ‚Ä¶</p></div></a><a href=/product/agentic_workforce/ class=related-post-card><div class=related-post-content><h4>Human-Mediated Agentic Workflows</h4><div class=related-post-meta><span class=related-post-date>July 13, 2025</span>
<span class=related-post-tags>#Product</span></div><p class=related-post-excerpt>Agentic Workforce Our current rate of adoption for agentic workforces has significant room for ‚Ä¶</p></div></a><a href=/product/search/ class=related-post-card><div class=related-post-content><h4>Search & Discovery Features</h4><div class=related-post-meta><span class=related-post-date>May 15, 2025</span>
<span class=related-post-tags>#Product</span></div><p class=related-post-excerpt>An analysis of traditional search paradigms and a framework for integrating AI capabilities into ‚Ä¶</p></div></a><a href=/posts/crowd_thesis/ class=related-post-card><div class=related-post-content><h4>Why People Care What Others Think</h4><div class=related-post-meta><span class=related-post-date>May 12, 2025</span>
<span class=related-post-tags>#Observations</span></div><p class=related-post-excerpt>In a world dominated by expert opinions and algorithm-driven content, there&rsquo;s something ‚Ä¶</p></div></a></div></div><style>.related-posts{margin-top:3rem;padding-top:2rem;border-top:1px solid var(--border);max-width:var(--content-width,720px);margin-left:auto;margin-right:auto;width:100%;padding-left:var(--gap);padding-right:var(--gap)}.related-posts h3{margin-bottom:1.5rem;font-size:1.5rem;font-weight:600;color:var(--primary)}.related-posts-grid{display:grid;grid-template-columns:repeat(auto-fill,minmax(300px,1fr));gap:1.5rem}.related-post-card{display:block;padding:1.2rem;border-radius:var(--radius);background:var(--code-bg);border:1px solid var(--border);box-shadow:var(--shadow);transition:transform .2s,box-shadow .2s;text-decoration:none}.related-post-card:hover{transform:translateY(-3px);box-shadow:0 5px 15px rgba(0,0,0,.1)}:root[data-theme=dark] .related-post-card:hover{box-shadow:0 5px 15px rgba(0,0,0,.4)}.related-post-card h4{margin:0 0 .6rem;font-size:1.1rem;font-weight:500;color:var(--primary);line-height:1.3}.related-post-meta{display:flex;justify-content:space-between;margin-bottom:.8rem;font-size:.85rem;color:var(--secondary)}.related-post-excerpt{font-size:.95rem;color:var(--content);line-height:1.5;margin:0}@media(max-width:768px){.related-posts-grid{grid-template-columns:1fr}}</style><style>body{background-color:var(--theme)}.post-single{background-color:var(--entry);border-radius:var(--radius);max-width:var(--content-width,720px);width:100%;margin-left:auto;margin-right:auto;padding:var(--gap);margin-bottom:var(--gap);box-shadow:var(--shadow)}.post-content{margin-top:var(--content-gap);color:var(--content)}.post-content h1,.post-content h2,.post-content h3,.post-content h4{margin:1.5em 0 .5em;color:var(--primary)}</style></main><footer class=footer><span>&copy; 2025 <a href=https://chenterry.com/>Terry Chen</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span><div class=archived-link><span style=font-size:.85em;color:#888;margin-top:8px;display:block>To view archived content, <a href=/archived/ style=color:#666;text-decoration:underline>click here</a></span></div></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>window.addEventListener("error",function(e){console.error("Page error:",e.error),console.error("Error details:",{message:e.message,filename:e.filename,lineno:e.lineno,colno:e.colno})}),history.scrollRestoration&&(history.scrollRestoration="manual"),window.addEventListener("load",function(){window.scrollTo(0,0)}),window.addEventListener("pageshow",function(e){e.persisted&&window.scrollTo(0,0)});let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>