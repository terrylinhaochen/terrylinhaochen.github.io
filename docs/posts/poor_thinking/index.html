<!DOCTYPE html>
<html lang="en" dir="auto">

<head>
<meta name="description" content="How the ease of LLM-generated content masks poor reasoning and why developing domain expertise remains crucial for meaningful innovation beyond automated productivity gains.">
<meta name="keywords" content="Posts, Observations">
<meta name="author" content="Terry Chen">
<meta name="robots" content="index, follow">
<meta name="language" content="en-us">
<meta name="revisit-after" content="7 days">
<meta name="distribution" content="global">
<meta name="rating" content="general">
<link rel="canonical" href="https://chenterry.com/posts/poor_thinking/">


<meta property="og:title" content="Using LLMs as a Cover up for Poor Thinking | Terry Chen">
<meta property="og:description" content="How the ease of LLM-generated content masks poor reasoning and why developing domain expertise remains crucial for meaningful innovation beyond automated productivity gains.">
<meta property="og:type" content="article">
<meta property="og:url" content="https://chenterry.com/posts/poor_thinking/">
<meta property="og:site_name" content="Terry Chen">
<meta property="og:locale" content="en-us">

<meta property="article:published_time" content="2025-06-16T00:00:00Z">
<meta property="article:modified_time" content="2025-06-16T00:00:00Z">
<meta property="article:author" content="Terry Chen">


<meta property="article:tag" content="Posts">

<meta property="article:tag" content="Observations">






<meta property="og:image" content="https://chenterry.com/images/profile.jpg">
<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="630">
<meta property="og:image:alt" content="Terry Chen">




<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@terrychen_ai">
<meta name="twitter:creator" content="@terrychen_ai">
<meta name="twitter:title" content="Using LLMs as a Cover up for Poor Thinking | Terry Chen">
<meta name="twitter:description" content="How the ease of LLM-generated content masks poor reasoning and why developing domain expertise remains crucial for meaningful innovation beyond automated productivity gains.">


<meta name="twitter:image" content="https://chenterry.com/images/profile.jpg">
<meta name="twitter:image:alt" content="Terry Chen">





<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Using LLMs as a Cover up for Poor Thinking",
  "datePublished": "2025-06-16T00:00:00Z",
  "dateModified": "2025-06-16T00:00:00Z",
  "author": {
    "@type": "Person",
    "name": "Terry Chen",
    "url": "https:\/\/chenterry.com\/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Terry Chen",
    "logo": {
      "@type": "ImageObject",
      "url": "https:\/\/chenterry.com\/images/profile.jpg"
    }
  },
  "description": "How the ease of LLM-generated content masks poor reasoning and why developing domain expertise remains crucial for meaningful innovation beyond automated productivity gains.",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https:\/\/chenterry.com\/posts\/poor_thinking\/"
  },
  "keywords": "Posts, Observations",
  "articleSection": "posts"
  ,
  "image": {
    "@type": "ImageObject",
    "url": "https:\/\/chenterry.com\/images\/profile.jpg",
    "width": 1200,
    "height": 630
  }
}
</script>




<meta name="article:published_time" content="2025-06-16T00:00:00Z">
<meta name="article:modified_time" content="2025-06-16T00:00:00Z">



<meta name="googlebot" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">
<meta name="bingbot" content="index, follow">
<meta name="slurp" content="index, follow">
<meta name="duckduckbot" content="index, follow">



<meta name="section" content="posts">


<meta name="content-type" content="posts">



<meta name="geo.region" content="US">
<meta name="geo.placename" content="United States">
<meta name="language" content="en-us">
<meta http-equiv="content-language" content="en-us">





<meta property="og:determiner" content="the">
<meta property="og:rich_attachment" content="true">

<meta property="og:updated_time" content="2025-06-16T00:00:00Z">



<meta name="format-detection" content="telephone=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="default">
<meta name="apple-mobile-web-app-title" content="Terry Chen">


<meta http-equiv="Cache-Control" content="public, max-age=31536000">
<meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">


<meta name="referrer" content="strict-origin-when-cross-origin">



<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "name": "Home",
      "item": "https:\/\/chenterry.com\/"
    }
    ,
    {
      "@type": "ListItem", 
      "position": 2,
      "name": "Posts",
      "item": "https:\/\/chenterry.com\/posts/"
    }
    
    ,
    {
      "@type": "ListItem",
      "position": 3,
      "name": "Using LLMs as a Cover up for Poor Thinking",
      "item": "https:\/\/chenterry.com\/posts\/poor_thinking\/"
    }
    
  ]
}
</script>



<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="dns-prefetch" href="//www.google-analytics.com">
<link rel="dns-prefetch" href="//www.googletagmanager.com">


<meta name="msapplication-config" content="/browserconfig.xml">
<meta name="application-name" content="Terry Chen">



<meta name="DC.type" content="Text">
<meta name="DC.format" content="text/html">
<meta name="DC.identifier" content="https://chenterry.com/posts/poor_thinking/">
<meta name="DC.date" content="2025-06-16">
<meta name="DC.creator" content="Terry Chen">
<meta name="DC.publisher" content="Terry Chen">
<meta name="DC.rights" content="© 2025 Terry Chen. All rights reserved.">
 <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow"><title>Using LLMs as a Cover up for Poor Thinking | Terry Chen</title>
<meta name="keywords" content="Posts, Observations">
<meta name="author" content="Terry Chen">
<link rel="canonical" href="https://chenterry.com/posts/poor_thinking/">
    <link crossorigin="anonymous" href="/assets/css/stylesheet.f495fe1dedb119b2969e64d021ab84ebb9f24a5086308bd0222ece1b182e151e.css" integrity="sha256-9JX&#43;He2xGbKWnmTQIauE67nySlCGMIvQIi7OGxguFR4=" rel="preload stylesheet" as="style"><link rel="icon" href="https://chenterry.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://chenterry.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://chenterry.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://chenterry.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://chenterry.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="manifest" href="https://chenterry.com/manifest.json"><link rel="alternate" hreflang="en" href="https://chenterry.com/posts/poor_thinking/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>😜</text></svg>" type="image/svg+xml">

<link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>😜</text></svg>"> 
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-M6GS8Q702L"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-M6GS8Q702L');
        }
      </script><meta property="og:url" content="https://chenterry.com/posts/poor_thinking/">
  <meta property="og:site_name" content="Terry Chen">
  <meta property="og:title" content="Using LLMs as a Cover up for Poor Thinking">
  <meta property="og:description" content="How the ease of LLM-generated content masks poor reasoning and why developing domain expertise remains crucial for meaningful innovation beyond automated productivity gains.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-06-16T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-06-16T00:00:00+00:00">
    <meta property="article:tag" content="Posts">
    <meta property="article:tag" content="Observations">
      <meta property="og:image" content="https://chenterry.com/images/profile.jpg">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://chenterry.com/images/profile.jpg">
<meta name="twitter:title" content="Using LLMs as a Cover up for Poor Thinking">
<meta name="twitter:description" content="How the ease of LLM-generated content masks poor reasoning and why developing domain expertise remains crucial for meaningful innovation beyond automated productivity gains.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://chenterry.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Using LLMs as a Cover up for Poor Thinking",
      "item": "https://chenterry.com/posts/poor_thinking/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Using LLMs as a Cover up for Poor Thinking",
  "name": "Using LLMs as a Cover up for Poor Thinking",
  "description": "How the ease of LLM-generated content masks poor reasoning and why developing domain expertise remains crucial for meaningful innovation beyond automated productivity gains.",
  "keywords": [
    "Posts", "Observations"
  ],
  "articleBody": "Every now and then I come across some article or discussion that just feels plain and mundane. All the words seem to make sense, yet at the same time, they feel almost predictable. Despite how well articulated these ideas were - be it in carefully formatted slide decks or confidently delivered proses - they fail to amaze. Ever since November of 2022, the ability to articulate words cohesively (I’m purposefully not using the word coherently) has become table stakes. In a society where frankly most work is evaluated on completion and length, LLMs have led to a rapid advancement of productivity. Yet I think we should make certain clarifications here - productivity gain is in automating repetitive and redundant tasks, this does not apply to all tasks, in fact, using GPT for sophisticated reasoning is almost guarenteed to produce mediocore results.\nLet’s admit it, a big chunck of the work we do everyday some one else can do. The tedius, repetitive, and standard operating procedure tasks don’t require drastic innovation, they just need a criteria to be evaluated on and human hours, lots of it. This is work that AI could automate. However, an issue I’ve been seeing recently is people using AI as a catch all for tasks that should involve a level of reasoning and for a lack of better word, taste. Product managers go asking LLMs for user pain points, product features, and even feedback for products. However, the thing to note here is that a LLM is probablistic - it’s trained on generalization - when you build for all, you build for none. This is why I caution my self and take a step back each time an LLM produces a lengthy blob of text that I don’t see obvious issues with through the first run - do I have enough knowledge in the field to have good taste?\nThis to me is a fascinating topic. Although I have some ideas of how to best use LLMs. I now ask my self to read more before formulating a response. At worse, this would be developing enough text corpus to develop probablistic predictions. At best, I’d even be able to reason and build on some good ideas and push the field a bit further. Here are some of the papers / books I plan to be reading in the coming weeks:\nMagic Link - Information Software and the Graphical Interface by Bret Victor Man-Computer Symbiosis by J.C.R Licklider Augmenting Human Intellect: A Conceptual Framework by D.C. Engelbart. 6.25 Something I’ve just recently started to acknowledge (I’ve heard this repeated many times, but it sort of just sunk in today) is that we are actually fast approaching a period where ai moves beyond the traditional “copilot” and human-in-the-loop dynmaic, moving to fully autonomous teams capable to aligning goals and executing multi-step tasks over a long horizon. This would mean a dramatic shift in our workforce, where we would actually have a significant portion of workers be non-human entities. The industrial revolution and rise of the internet has led to specialization in the work we do: for internet products, we’d have software engineers (Research, QA, ML) , PMs, Designers, Marketers, but I see the line to become increasingly blurred as we progress.\n",
  "wordCount" : "543",
  "inLanguage": "en",
  "image": "https://chenterry.com/images/profile.jpg","datePublished": "2025-06-16T00:00:00Z",
  "dateModified": "2025-06-16T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Terry Chen"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://chenterry.com/posts/poor_thinking/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Terry Chen",
    "logo": {
      "@type": "ImageObject",
      "url": "https://chenterry.com/favicon.ico"
    }
  }
}
</script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-M6GS8Q702L"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'MEASUREMENT_ID');
</script><script type="application/ld+json">
{
  "@context": "https://schema.org",
  
  
  "@type": "BlogPosting",
  
  "headline": "Using LLMs as a Cover up for Poor Thinking",
  "image": "https:\/\/chenterry.com\/",
  "datePublished": "2025-06-16T00:00:00\u002b00:00",
  "dateModified": "2025-06-16T00:00:00\u002b00:00",
  "author": {
    "@type": "Person",
    "name": "Terry Chen"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Terry Chen",
    "logo": {
      "@type": "ImageObject",
      "url": "https:\/\/chenterry.com\/"
    }
  },
  "description": "How the ease of LLM-generated content masks poor reasoning and why developing domain expertise remains crucial for meaningful innovation beyond automated productivity gains.",
  
  
  "wordCount": "543",
  "timeRequired": "PT2M"
  
}
</script>


 

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "name": "Home",
      "item": "https:\/\/chenterry.com\/"
    }
    
    ,{
      "@type": "ListItem",
      "position": 2,
      "name": "Posts",
      "item": "https:\/\/chenterry.com\/posts/"
    }
    
    
    ,{
      "@type": "ListItem",
      "position": 3,
      "name": "Using LLMs as a Cover up for Poor Thinking",
      "item": "https:\/\/chenterry.com\/posts\/poor_thinking\/"
    }
  ]
}
</script>
 



<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Person",
  "name": "Terry Chen",
  "url": "https:\/\/chenterry.com\/",
  "sameAs": [
    "https://www.linkedin.com/in/terry-chen-3b44911a4/",
    "https://github.com/terrylinhaochen"
  ],
  "jobTitle": "AI Product Engineer",
  "description": "AI Product Engineer and Investor exploring multi-agent systems, content understanding, and emerging technology investments",
  "knowsAbout": [
    "Artificial Intelligence",
    "Product Engineering", 
    "Investment Analysis",
    "Multi-Agent Systems",
    "Machine Learning",
    "Technology Strategy"
  ],
  "alumniOf": "Northwestern University"
}
</script>



















<style>
   
  link[rel="icon"] {
    content: url("data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>😜</text></svg>");
  }
</style> 
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://chenterry.com/" accesskey="h" title="Terry Chen (Alt + H)">Terry Chen</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            
            <li>
                <a href="/posts/" title="Posts">
                    <span class="active">
                        Posts
                    </span>
                </a>
            </li>
            <li>
                <a href="/product/" title="Product">
                    <span>
                        Product
                    </span>
                </a>
            </li>
            <li>
                <a href="/investing/" title="Investing">
                    <span>
                        Investing
                    </span>
                </a>
            </li>
            <li>
                <a href="/search/" title="Explore" accesskey="/">
                    <span>
                        Explore
                    </span>
                </a>
            </li>
            <li>
                <a href="/about/" title="About">
                    <span>
                        About
                    </span>
                </a>
            </li>
        </ul>
    </nav>
</header> <main class="main">
<article class="post-single">
  <header class="post-header">
    <h1 class="post-title">Using LLMs as a Cover up for Poor Thinking</h1>
    
    
    <div class="post-meta">
      By Terry Chen • 
      <time>June 16, 2025</time>
    </div>
  </header>
  
  
  <div class="post-content">
    <p>Every now and then I come across some article or discussion that just feels plain and mundane. All the words seem to make sense, yet at the same time, they feel almost predictable. Despite how well articulated these ideas were - be it in carefully formatted slide decks or confidently delivered proses - they fail to amaze. Ever since November of 2022, the ability to articulate words cohesively (I&rsquo;m purposefully not using the word coherently) has become table stakes. In a society where frankly most work is evaluated on completion and length, LLMs have led to a rapid advancement of productivity. Yet I think we should make certain clarifications here - productivity gain is in automating repetitive and redundant tasks, this does not apply to all tasks, in fact, using GPT for sophisticated reasoning is almost guarenteed to produce mediocore results.</p>
<p>Let&rsquo;s admit it, a big chunck of the work we do everyday some one else can do. The tedius, repetitive, and standard operating procedure tasks don&rsquo;t require drastic innovation, they just need a criteria to be evaluated on and human hours, lots of it. This is work that AI could automate. However, an issue I&rsquo;ve been seeing recently is people using AI as a catch all for tasks that should involve a level of reasoning and for a lack of better word, taste. Product managers go asking LLMs for user pain points, product features, and even feedback for products. However, the thing to note here is that a LLM is probablistic - it&rsquo;s trained on generalization - when you build for all, you build for none. This is why I caution my self and take a step back each time an LLM produces a lengthy blob of text that I don&rsquo;t see obvious issues with through the first run - do I have enough knowledge in the field to have good taste?</p>
<p>This to me is a fascinating topic. Although I have some ideas of how to best use LLMs. I now ask my self to read more before formulating a response. At worse, this would be developing enough text corpus to develop probablistic predictions. At best, I&rsquo;d even be able to reason and build on some good ideas and push the field a bit further. Here are some of the papers / books I plan to be reading in the coming weeks:</p>
<ol>
<li>Magic Link - Information Software and the Graphical Interface by Bret Victor</li>
<li>Man-Computer Symbiosis by J.C.R Licklider</li>
<li>Augmenting Human Intellect: A Conceptual Framework by D.C. Engelbart.</li>
</ol>
<p>6.25 Something I&rsquo;ve just recently started to acknowledge (I&rsquo;ve heard this repeated many times, but it sort of just sunk in today) is that we are actually fast approaching a period where ai moves beyond the traditional &ldquo;copilot&rdquo; and human-in-the-loop dynmaic, moving to fully autonomous teams capable to aligning goals and executing multi-step tasks over a long horizon. This would mean a dramatic shift in our workforce, where we would actually have a significant portion of workers be non-human entities. The industrial revolution and rise of the internet has led to specialization in the work we do: for internet products, we&rsquo;d have software engineers (Research, QA, ML) , PMs, Designers, Marketers, but I see the line to become increasingly blurred as we progress.</p>

  </div>
  
  
  
  <footer class="post-footer">
    <div class="post-tags">
      
      <a href="/tags/posts">Posts</a>
      
      <a href="/tags/observations">Observations</a>
      
    </div>
  </footer>
  

  
  

  
  
</article>




<div class="related-posts">
  <h3>Related Articles</h3>
  <div class="related-posts-grid">
    
    <a href="/posts/generation_distribution/" class="related-post-card">
      <div class="related-post-content">
        <h4>Value Add of AI: Generation as Distribution</h4>
        <div class="related-post-meta">
          <span class="related-post-date">May 8, 2025</span>
          
          <span class="related-post-tags">
            #Observations
          </span>
          
        </div>
        <p class="related-post-excerpt">The Evolution of AI Value The first wave of generative AI focused primarily on content creation - …</p>
      </div>
    </a>
    
    <a href="/main-themes/human-quirks/" class="related-post-card">
      <div class="related-post-content">
        <h4>Human Quirks</h4>
        <div class="related-post-meta">
          <span class="related-post-date">October 1, 2024</span>
          
          <span class="related-post-tags">
            #Observations
          </span>
          
        </div>
        <p class="related-post-excerpt">Observing and understanding the strange quirks of individuals and crowds What makes humans truly …</p>
      </div>
    </a>
    
    <a href="/main-themes/tech-history/" class="related-post-card">
      <div class="related-post-content">
        <h4>Tech History</h4>
        <div class="related-post-meta">
          <span class="related-post-date">March 19, 2024</span>
          
          <span class="related-post-tags">
            #Observations
          </span>
          
        </div>
        <p class="related-post-excerpt">Exploring the evolution of technology and its impact on society Understanding the past is crucial …</p>
      </div>
    </a>
    
    <a href="/posts/questions-new-bottleneck-learning/" class="related-post-card">
      <div class="related-post-content">
        <h4>Questions as the New Bottleneck in Learning</h4>
        <div class="related-post-meta">
          <span class="related-post-date">May 14, 2025</span>
          
          <span class="related-post-tags">
            #Posts
          </span>
          
        </div>
        <p class="related-post-excerpt">Introduction We live in an era of unprecedented access to information. The web contains almost all …</p>
      </div>
    </a>
    
  </div>
</div>

<style>
  .related-posts {
    margin-top: 3rem;
    padding-top: 2rem;
    border-top: 1px solid var(--border);
    max-width: var(--content-width, 720px);
    margin-left: auto;
    margin-right: auto;
    width: 100%;
    padding-left: var(--gap);
    padding-right: var(--gap);
  }
  
  .related-posts h3 {
    margin-bottom: 1.5rem;
    font-size: 1.5rem;
    font-weight: 600;
    color: var(--primary);
  }
  
  .related-posts-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
    gap: 1.5rem;
  }
  
  .related-post-card {
    display: block;
    padding: 1.2rem;
    border-radius: var(--radius);
    background: var(--code-bg);
    border: 1px solid var(--border);
    box-shadow: var(--shadow);
    transition: transform 0.2s, box-shadow 0.2s;
    text-decoration: none;
  }
  
  .related-post-card:hover {
    transform: translateY(-3px);
    box-shadow: 0 5px 15px rgba(0,0,0,0.1);
  }
  
  :root[data-theme="dark"] .related-post-card:hover {
    box-shadow: 0 5px 15px rgba(0,0,0,0.4);
  }
  
  .related-post-card h4 {
    margin: 0 0 0.6rem 0;
    font-size: 1.1rem;
    font-weight: 500;
    color: var(--primary);
    line-height: 1.3;
  }
  
  .related-post-meta {
    display: flex;
    justify-content: space-between;
    margin-bottom: 0.8rem;
    font-size: 0.85rem;
    color: var(--secondary);
  }
  
  .related-post-excerpt {
    font-size: 0.95rem;
    color: var(--content);
    line-height: 1.5;
    margin: 0;
  }
  
  @media (max-width: 768px) {
    .related-posts-grid {
      grid-template-columns: 1fr;
    }
  }
</style>
 

<style>
   
  body {
    background-color: var(--theme);
  }
  
  .post-single {
    background-color: var(--entry);
    border-radius: var(--radius);
     
    max-width: var(--content-width, 720px);
    width: 100%;
    margin-left: auto;
    margin-right: auto;
    padding: var(--gap);
    margin-bottom: var(--gap);
    box-shadow: var(--shadow);
  }
  
  .post-content {
    margin-top: var(--content-gap);
    color: var(--content);
  }
  
  .post-content h1,
  .post-content h2,
  .post-content h3,
  .post-content h4 {
    margin: 1.5em 0 0.5em;
    color: var(--primary);
  }

   
  .version-history {
    margin-top: 2rem;
    padding: 1.5rem;
    background-color: var(--code-bg);
    border-radius: var(--radius);
    border-left: 4px solid var(--primary);
  }

  .version-history h3 {
    margin: 0 0 1rem 0;
    color: var(--primary);
    font-size: 1.1rem;
  }

  .version-item {
    margin-bottom: 1rem;
    padding-bottom: 0.75rem;
    border-bottom: 1px solid var(--border);
  }

  .version-item:last-child {
    border-bottom: none;
    margin-bottom: 0;
  }

  .version-header {
    display: flex;
    align-items: center;
    gap: 0.75rem;
    margin-bottom: 0.25rem;
    flex-wrap: wrap;
  }

  .version-number {
    font-weight: bold;
    color: var(--primary);
    font-family: var(--font-mono, monospace);
  }

  .version-date {
    color: var(--secondary);
    font-size: 0.9rem;
  }

  .current-badge {
    background-color: var(--primary);
    color: var(--theme);
    padding: 0.2rem 0.5rem;
    border-radius: 0.25rem;
    font-size: 0.8rem;
    font-weight: bold;
  }

  .view-commits {
    color: var(--primary);
    text-decoration: none;
    font-size: 0.9rem;
    padding: 0.2rem 0.5rem;
    border: 1px solid var(--primary);
    border-radius: 0.25rem;
    transition: all 0.2s ease;
    display: inline-flex;
    align-items: center;
    gap: 0.25rem;
  }

  .view-commits:hover {
    background-color: var(--primary);
    color: var(--theme);
  }

  .view-commits svg {
    width: 14px;
    height: 14px;
  }

  .git-info {
    margin-top: 1rem;
    text-align: center;
    color: var(--secondary);
    font-style: italic;
  }

  .version-changes {
    color: var(--content);
    font-style: italic;
    margin-bottom: 0.25rem;
    font-size: 0.95rem;
  }

  .version-summary {
    color: var(--secondary);
    font-size: 0.9rem;
  }

  .update-info {
    margin-top: 1rem;
    text-align: center;
    color: var(--secondary);
    border-top: 1px solid var(--border);
    padding-top: 1rem;
  }
</style>

    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="https://chenterry.com/">Terry Chen</a></span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
    
    
    <div class="archived-link">
        <span style="font-size: 0.85em; color: #888; margin-top: 8px; display: block;">
            To view archived content, <a href="/archived/" style="color: #666; text-decoration: underline;">click here</a>
        </span>
    </div>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    
    window.addEventListener('error', function(e) {
        console.error('Page error:', e.error);
        console.error('Error details:', {
            message: e.message,
            filename: e.filename,
            lineno: e.lineno,
            colno: e.colno
        });
    });

    
    if (history.scrollRestoration) {
        history.scrollRestoration = 'manual';
    }
    
    
    window.addEventListener('load', function() {
        window.scrollTo(0, 0);
    });
    
    
    window.addEventListener('pageshow', function(event) {
        if (event.persisted) {
            window.scrollTo(0, 0);
        }
    });

    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script> </body>

</html>
