<!DOCTYPE html>
<html lang="en" dir="auto">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
<meta name="description" content="Exploring the intersection of AI-generated content and human creativity. Analysis of creative workflows, multimodal interactions, and the future of content creation in the AI era.">
<meta name="keywords" content="AI creativity, content generation, creative workflows, multimodal AI, content understanding, AI-generated content, creative technology, content creation">
<meta name="author" content="Terry Chen">
<meta name="robots" content="index, follow">
<meta name="language" content="en-us">
<meta name="revisit-after" content="7 days">
<meta name="distribution" content="global">
<meta name="rating" content="general">
<link rel="canonical" href="http://localhost:1313/posts/essense_of_creativity/">


<meta property="og:title" content="Essence of Creativity: Future of Creative Work | Terry Chen">
<meta property="og:description" content="Exploring the intersection of AI-generated content and human creativity. Analysis of creative workflows, multimodal interactions, and the future of content creation in the AI era.">
<meta property="og:type" content="article">
<meta property="og:url" content="http://localhost:1313/posts/essense_of_creativity/">
<meta property="og:site_name" content="Terry Chen">
<meta property="og:locale" content="en-us">

<meta property="article:published_time" content="2024-08-25T00:00:00Z">
<meta property="article:modified_time" content="2024-08-25T00:00:00Z">
<meta property="article:author" content="Terry Chen">


<meta property="article:tag" content="Observations">

<meta property="article:tag" content="Entrepreneurship">

<meta property="article:tag" content="Product">

<meta property="article:tag" content="Posts">




<meta property="article:section" content="tiktok">





<meta property="og:image" content="http://localhost:1313/images/profile.jpg">
<meta property="og:image:width" content="1200">
<meta property="og:image:height" content="630">
<meta property="og:image:alt" content="Terry Chen">




<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@terrychen_ai">
<meta name="twitter:creator" content="@terrychen_ai">
<meta name="twitter:title" content="Essence of Creativity: Future of Creative Work | Terry Chen">
<meta name="twitter:description" content="Exploring the intersection of AI-generated content and human creativity. Analysis of creative workflows, multimodal interactions, and the future of content creation in the AI era.">


<meta name="twitter:image" content="http://localhost:1313/images/profile.jpg">
<meta name="twitter:image:alt" content="Terry Chen">





<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Essence of Creativity: Future of Creative Work",
  "datePublished": "2024-08-25T00:00:00Z",
  "dateModified": "2024-08-25T00:00:00Z",
  "author": {
    "@type": "Person",
    "name": "Terry Chen",
    "url": "http:\/\/localhost:1313\/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Terry Chen",
    "logo": {
      "@type": "ImageObject",
      "url": "http:\/\/localhost:1313\/images/profile.jpg"
    }
  },
  "description": "Exploring the intersection of AI-generated content and human creativity. Analysis of creative workflows, multimodal interactions, and the future of content creation in the AI era.",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http:\/\/localhost:1313\/posts\/essense_of_creativity\/"
  },
  "keywords": "AI creativity, content generation, creative workflows, multimodal AI, content understanding, AI-generated content, creative technology, content creation",
  "articleSection": "tiktok"
  ,
  "image": {
    "@type": "ImageObject",
    "url": "http:\/\/localhost:1313\/images\/profile.jpg",
    "width": 1200,
    "height": 630
  }
}
</script>




<meta name="article:published_time" content="2024-08-25T00:00:00Z">
<meta name="article:modified_time" content="2024-08-25T00:00:00Z">



<meta name="googlebot" content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1">
<meta name="bingbot" content="index, follow">
<meta name="slurp" content="index, follow">
<meta name="duckduckbot" content="index, follow">



<meta name="section" content="posts">


<meta name="content-type" content="posts">



<meta name="geo.region" content="US">
<meta name="geo.placename" content="United States">
<meta name="language" content="en-us">
<meta http-equiv="content-language" content="en-us">





<meta property="og:determiner" content="the">
<meta property="og:rich_attachment" content="true">

<meta property="og:updated_time" content="2024-08-25T00:00:00Z">



<meta name="format-detection" content="telephone=no">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="default">
<meta name="apple-mobile-web-app-title" content="Terry Chen">


<meta http-equiv="Cache-Control" content="public, max-age=31536000">
<meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">


<meta name="referrer" content="strict-origin-when-cross-origin">



<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "name": "Home",
      "item": "http:\/\/localhost:1313\/"
    }
    ,
    {
      "@type": "ListItem", 
      "position": 2,
      "name": "Posts",
      "item": "http:\/\/localhost:1313\/posts/"
    }
    
    ,
    {
      "@type": "ListItem",
      "position": 3,
      "name": "Essence of Creativity: Future of Creative Work",
      "item": "http:\/\/localhost:1313\/posts\/essense_of_creativity\/"
    }
    
  ]
}
</script>



<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link rel="dns-prefetch" href="//www.google-analytics.com">
<link rel="dns-prefetch" href="//www.googletagmanager.com">


<meta name="msapplication-config" content="/browserconfig.xml">
<meta name="application-name" content="Terry Chen">



<meta name="DC.type" content="Text">
<meta name="DC.format" content="text/html">
<meta name="DC.identifier" content="http://localhost:1313/posts/essense_of_creativity/">
<meta name="DC.date" content="2024-08-25">
<meta name="DC.creator" content="Terry Chen">
<meta name="DC.publisher" content="Terry Chen">
<meta name="DC.rights" content="¬© 2025 Terry Chen. All rights reserved.">
 <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow"><title>Essence of Creativity: Future of Creative Work | Terry Chen</title>
<meta name="keywords" content="AI creativity, content generation, creative workflows, multimodal AI, content understanding, AI-generated content, creative technology, content creation">
<meta name="author" content="Terry Chen">
<link rel="canonical" href="http://localhost:1313/posts/essense_of_creativity/">
    <link crossorigin="anonymous" href="/assets/css/stylesheet.f495fe1dedb119b2969e64d021ab84ebb9f24a5086308bd0222ece1b182e151e.css" integrity="sha256-9JX&#43;He2xGbKWnmTQIauE67nySlCGMIvQIi7OGxguFR4=" rel="preload stylesheet" as="style"><link rel="icon" href="http://localhost:1313/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:1313/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:1313/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:1313/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:1313/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="manifest" href="http://localhost:1313/manifest.json"><link rel="alternate" hreflang="en" href="http://localhost:1313/posts/essense_of_creativity/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script src="https://analytics.ahrefs.com/analytics.js" data-key="RfhOdZ+DOpWNlhV9QqLgTQ" async></script>


<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üòú</text></svg>" type="image/svg+xml">

<link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üòú</text></svg>"> 
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-M6GS8Q702L"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-M6GS8Q702L');
        }
      </script><meta property="og:url" content="http://localhost:1313/posts/essense_of_creativity/">
  <meta property="og:site_name" content="Terry Chen">
  <meta property="og:title" content="Essence of Creativity: Future of Creative Work">
  <meta property="og:description" content="Exploring the intersection of AI-generated content and human creativity. Analysis of creative workflows, multimodal interactions, and the future of content creation in the AI era.">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2024-08-25T00:00:00+00:00">
    <meta property="article:modified_time" content="2024-08-25T00:00:00+00:00">
    <meta property="article:tag" content="Observations">
    <meta property="article:tag" content="Entrepreneurship">
    <meta property="article:tag" content="Product">
    <meta property="article:tag" content="Posts">
      <meta property="og:image" content="http://localhost:1313/images/profile.jpg">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://localhost:1313/images/profile.jpg">
<meta name="twitter:title" content="Essence of Creativity: Future of Creative Work">
<meta name="twitter:description" content="Exploring the intersection of AI-generated content and human creativity. Analysis of creative workflows, multimodal interactions, and the future of content creation in the AI era.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "http://localhost:1313/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Essence of Creativity: Future of Creative Work",
      "item": "http://localhost:1313/posts/essense_of_creativity/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Essence of Creativity: Future of Creative Work",
  "name": "Essence of Creativity: Future of Creative Work",
  "description": "Exploring the intersection of AI-generated content and human creativity. Analysis of creative workflows, multimodal interactions, and the future of content creation in the AI era.",
  "keywords": [
    "AI creativity", "content generation", "creative workflows", "multimodal AI", "content understanding", "AI-generated content", "creative technology", "content creation"
  ],
  "articleBody": "Is it creative to screenshot someone else‚Äôs video and caption it with other people‚Äôs comments? This seemingly simple question hits every creator making rent from content: if AI can remix, analyze, and generate at scale, what‚Äôs left that‚Äôs genuinely yours?\nThrough building AI content tools, I‚Äôve discovered the real opportunity isn‚Äôt AI replacing creators‚Äîit‚Äôs AI helping creators understand the massive amounts of content data around them to find genuinely fresh angles. Think of it as having a research team that can analyze millions of posts, comments, and engagement patterns in seconds, then surface the insights that lead to truly original work.\nTikTok's content creation interface: Where creators combine video, audio, and engagement elements to build viral content\nNote (Nov 4th, 2025): I was actually able to speak to the head of strategy for Mr.Beast and surprisingly enough (or not surprisingly) this is exactly what they are doing and what makes their content so successful - they look for outliers in mass amounts of data - finding videos that genuinely spark viewers‚Äô interest, even if it‚Äôs in a different domain - think a Minecraft simulation with 100 players on each island (male/female) and recreating that with actual human participants.\nComment analytics revealing audience engagement patterns and content resonance across different demographics\nContent structure breakdown: How platforms organize multimodal content across video, interaction data, and comments\nLet‚Äôs touch on how, as we can see in this breakdown, what gets abstracted away to just tabular blobs of text contains much information on how information is presented and interacted with. The visual elements and text within the video grab a user‚Äôs attention, while the audio provides voiceover narrating the message (or sometimes relevant background music). The titles and description provide detailed information on the video, while the comments section‚Äîsomething often overlooked in current processing workflows‚Äîpresents a goldmine of user interaction and feedback.\nThe primary comments act as tier 1 opinions, with responses and likes serving as interaction trackers. If users have the same opinion, they‚Äôll usually hit the like button instead of posting the exact same thing again. By linking the content of the video to actual interactions (both tier 1 and tier 2), we get a polling of audience feedback that is timely and beyond anything we can do in the same amount of time with surveys or really any other kind of data collection.\nAI isn‚Äôt becoming creative‚Äîit‚Äôs becoming the ultimate creative research assistant. While generative AI struggles to produce truly fresh perspectives, it excels at helping us understand information and generate new insights that lead to genuinely creative work.\nWhat Constitutes Creative Work? To understand AI‚Äôs role in creativity, we need to establish clear boundaries around what constitutes creative work. Consider the common practice of taking screenshots from viral videos and adding captions from popular comments. While this involves some editing, it‚Äôs essentially sophisticated copying that accelerates content diffusion while reducing the economic returns of original creation‚Äîwhat economist Schumpeter called ‚Äúcreative destruction‚Äù in reverse.\nUnderstanding how platforms structure multimodal content helps us see the complexity involved in creative work.\nReal creativity is about choosing a unique perspective. Content with contrast or conflict naturally captures our attention‚Äîthink of viral TikToks that expose workplace absurdities or Twitter threads that challenge conventional wisdom. But thoughtful, empathetic content is equally creative: the YouTube essayist who helps you understand your own anxiety, or the LinkedIn post that perfectly articulates what you‚Äôve been feeling about remote work.\nHere‚Äôs how I think about the creative ecosystem: there‚Äôs production (generating new content) and diffusion (deriving from or spreading existing content). AI‚Äôs sweet spot isn‚Äôt in either category alone‚Äîit‚Äôs in helping us understand massive amounts of information to find genuinely new angles and insights.\nRight now, creating professional-quality video requires hours of shooting, editing, and post-production. As AI gets better at handling video, audio, and text together, we‚Äôre heading toward a world where that same video could be produced in minutes. This changes everything about the creative economy, making tools that help you find new inspiration increasingly valuable. Through this creative assistance, we can achieve two main effects:\nTwo primary effects of AI creative assistance: Inspiration acquisition and content derivation\nInspiration acquisition: Accelerating original content production by collapsing the draft ‚Üí iterate loop Content derivation: Accelerating the diffusion of quality creative work across formats and channels Content Understanding for Enhanced Generation How can we make language models produce outputs that meet our expectations? This challenge breaks down into two distinct problems: (1) we don‚Äôt know what our ideal output looks like, and (2) we know what we want, but the language model doesn‚Äôt understand us.\nMost teams focus on the second problem through a toolkit of techniques: model alignment (training AI to follow human preferences), prompting (crafting better instructions), few-shot learning (training AI with just a few examples), retrieval-augmented generation or RAG (helping AI access specific databases), fine-tuning (customizing AI for specific tasks), and memory systems (helping AI remember context across conversations). But companies are rapidly commoditizing these approaches‚Äîmany solutions are open-sourced, which explains why so many generative products deliver roughly comparable results.\nDifferent types of AI workflows: From basic generation to iterative collaboration\nThe real differentiation lies in how we adapt engineering and data processing to specific business scenarios‚Äîand more importantly, in solving the first problem: helping users understand what they actually want to create.\nAugust 2025: Recently I was asked about what the role of a PM in building technical products stands, especially given how much of the model side work is handled by technical teams. I think the answer, in short, is understanding of the product, and making sense of data in relation to how they are communicated and what they express. One may deal with numbers, but it‚Äôs harder to actually understand the people that make up those numbers. In the concrete example of multimodal content understanding, it‚Äôs being able to preserve the very granularity that makes this data so valuable, and proposing technical solutions‚Äîmodality alignment, weighted clustering, agent triage, content rewrite, etc.\nBrand Understanding and AI Integration Brand intelligence platform: AI systems learning to understand brand voice, visual identity, and content guidelines for contextual generation\nThe evolution toward brand-aware AI represents a significant shift in content generation capabilities. Instead of producing generic output that requires extensive human editing, these systems can understand context‚Äîwhat works for a luxury brand versus a startup, what tone resonates with different demographics, what visual styles align with brand guidelines.\nNovember 2025: I saw the recent release of Google Pomelli and I think this is a great example of how a general purpose technology moves from research and public beta to a more grounded and applied case that delivers actual time saving and value. Like TypeFace, it‚Äôs essentially creating a brand kit to free users from prompting repeatedly, and often times not knowing how to most effectively describe their style.\nAI brand training interface: How multimodal brand kits teach AI systems to generate content that aligns with specific brand requirements\nThe training process involves feeding AI systems examples of successful brand content across multiple modalities‚Äîtext, images, videos, and audio. The system learns not just what the brand says, but how it says it, what visual elements it uses, and what emotional tone it maintains. This creates AI that can generate content that feels authentically on-brand without constant human oversight.\nReturning to the first problem‚Äî‚ÄúI don‚Äôt know what output I want‚Äù‚Äîthis stems from a lack of content understanding. Good script writing requires more than just hooks (‚ÄúYou won‚Äôt believe what happens next‚Äù), unique selling propositions (USPs), and calls-to-action (CTAs)‚Äîit needs a clear angle: content that resonates with the audience, fits the context, and achieves its purpose.\nSome products are building brand kits or audience profiles to guide more specific content generation through manually defined style rules or user personas. While these types of configurations will probably become standard, the real breakthrough would be connecting insight data with generation without requiring manual setup every time.\nUnderstanding User Needs Looking at the creative technology landscape, every category‚Äîad aggregation, competitor tracking, brand insights, performance analysis, content generation‚Äîhas 3-4 companies offering basically the same thing. The data products feel traditional, while the AI products often just add ChatGPT integrations to existing workflows.\nThe real opportunity lies in acquiring more granular data and creating smoother interactions. Instead of isolated tools, imagine connecting the entire creative production process where you can participate and adjust at each stage‚Äîfrom initial research through final publication.\nHere‚Äôs a simple way to think about product value: user value = new experience - old experience - replacement cost. Most products built on foundational language models with minor tweaks deliver limited incremental value. Users still need to craft personalized prompts, and outputs almost always require multiple rounds of editing before they‚Äôre usable.\nSo how do we increase incremental value? The answer isn‚Äôt just better AI‚Äîit‚Äôs better workflows.\nUser-Friendly Workflows Currently, creators mostly call upon individual capabilities or data, but single capabilities are insufficient for full-process script/video generation. Building workflows can help users connect various AI capabilities, reducing friction between tool switches.\nThe concept of ‚Äúworkflows, not skills‚Äù addresses user needs: many users currently need 5-10 AI capabilities to complete their creative work, with most capabilities being disconnected and requiring frequent switching. By establishing a clear workflow, users can more efficiently call upon relevant tools to complete their creative work.\nI used to think that simply connecting AI capabilities constitutes a workflow, but that‚Äôs like saying a toolbox is the same as knowing how to build a house. What we call ‚ÄúLanguage UI‚Äù is actually ‚ÄúPrompt UI‚Äù‚Äîit differs from true language interaction by missing the context and shared understanding present in human conversation.\nThink about the difference: you can tell a colleague ‚Äúmake this more engaging‚Äù and they understand your brand, audience, and context. With ChatGPT, you need to write a novel-length prompt every single time explaining who you are, what you‚Äôre building, and what ‚Äúengaging‚Äù means in your specific context.\nThe future workflow tools will have human-like elements‚Äîthey‚Äôll ask follow-up questions, remember previous conversations, and understand your specific goals without you having to explain everything from scratch. Current prompting is probably transitional; eventually, we‚Äôll eliminate the need for context-heavy prompts by building AI that understands your context and generates appropriate guidance automatically.\nMultimodal Interaction and Content Ecosystem Finally, let‚Äôs discuss modality. Given the characteristics of different modalities (text - easily editable, images - non-linear, video - linear), different scenarios should use different modalities. The same user may need different interactions in different contexts.\nUnderstanding Content Through Data Visualization The first layer of multimodal content understanding goes beyond traditional analytics. Rather than just tracking views and likes, the most interesting insights come from clustering comments and opinion spread by category‚Äîproduct feedback, creator engagement, emotional responses. This granular analysis reveals patterns in audience sentiment and helps creators understand not just what performs well, but why it resonates with different audience segments.\nVector visualization analysis: AI-powered semantic mapping revealing hidden relationships between content themes and audience preferences\nBrand intelligence extraction: Analyzing fine-grained insights from audience feedback and engagement patterns\nBut the real magic happens in semantic analysis. Vector embeddings can reveal hidden relationships between content themes that humans might miss. For example, videos about ‚Äúproductivity tips‚Äù might cluster surprisingly close to ‚Äúcooking tutorials‚Äù because both satisfy the same underlying need for life optimization. This kind of insight helps creators find unexpected angles and untapped niches.\nContent performance metrics: Comprehensive analysis tracking engagement patterns, reach optimization, and conversion effectiveness across content types\nThe final piece is comprehensive performance analysis that connects creative decisions to business outcomes. This isn‚Äôt just about vanity metrics‚Äîit‚Äôs about understanding which content patterns lead to sustainable audience growth, higher conversion rates, and long-term creator success. When you can see these patterns clearly, you can make more informed creative decisions.\nSwitching between modal forms (long/short/mixed) and modal types (text/image/audio/video) will become easier, essentially providing the same content with applicability across different scenarios. Users aren‚Äôt just people; they‚Äôre collections of needs. For instance, I might read text at the office due to setting constraints, watch videos while waiting in line with nothing to do, and listen to audio while driving or commuting. The same content may need three modalities (text/video/audio) connected based on the scenario. This could be further refined - people accelerate reading or listening for higher information intake. Finding ways to adapt the same content to different scenarios without increasing creation costs is another interesting challenge.\nCase Study: Voice Synthesis Take voice synthesis as an example. Technically, this technology is already quite mature‚Äîyou can clone a voice with just a few minutes of audio. Yet when most people think about AI voice cloning, they imagine phone scams. Sure, there are fun projects like AI David Attenborough narrating random videos, or OpenAI‚Äôs GPT-4o launch event that briefly simulated Samantha‚Äôs voice from ‚ÄúHer.‚Äù But the most creative use I‚Äôve seen comes from short video creators.\nI recently discovered a creator called ‚ÄúYi Tou Jue Lv‚Äù who makes derivative content based on ‚ÄúIn the Name of the People‚Äù (a 2017 Chinese political drama). Their videos consistently get 500K+ views by doing something brilliant: they take original footage but replace all the narration with AI-synthesized character voices speaking internal monologues and psychological commentary. The result feels like getting inside the characters‚Äô heads in a way the original show never offered.\nWhat makes this work is the creator‚Äôs deep understanding of the characters combined with AI‚Äôs ability to generate consistent, high-quality voice synthesis. They‚Äôre not just copying‚Äîthey‚Äôre creating a completely new layer of interpretation that audiences can‚Äôt get anywhere else.\nContrasting Audio \u0026 Text It‚Äôs fascinating how differently our brains process audio and text. When we read, we‚Äôre essentially interacting with a graphical user interface‚Äîscanning, jumping between sections, processing information at our own pace. We‚Äôve evolved sophisticated tools for text: highlighting, bookmarking, section headers, and search functions. Yet despite these advantages, text can feel less engaging than a good conversation.\nAudio interfaces evolution: From podcast consumption (left) to social audio saving (right)‚Äîplatforms adapting to our increasingly audio-first content behaviors and the need to preserve valuable conversations\nSpeaking, in contrast, is inherently linear and social. There‚Äôs something about the human voice that keeps us present‚Äîthe subtle shifts in tone, the natural pauses, the back-and-forth rhythm. It‚Äôs why we can stay engaged in a podcast while walking (and multitask), yet reading typically demands our full attention.\nThis contrast reveals something deeper about how we process information. Text excels at conveying complex ideas‚Äîwe can revisit difficult passages, cross-reference concepts, and process at our own speed. Audio shines in maintaining engagement and conveying emotion, even if the content itself is relatively simple. Perhaps the future lies not in choosing between these mediums, but in finding ways to combine their strengths. Imagine an interface that preserves the natural flow of conversation while adding the structural advantages of text‚Äîwhere you could navigate both temporally and conceptually, maintaining both engagement and comprehension.\nConclusion Roland Barthes' \"Death of the Author\": When content is created, interpretation rights transfer to the audience\nAs Roland Barthes suggested with ‚ÄúThe Death of the Author,‚Äù once content is created, interpretation rights transfer to the audience. We see this everywhere today‚ÄîYouTube channels that analyze every Marvel movie, TikTok accounts that remix old TV shows, podcast networks that dissect every episode of popular series.\nWith improvements in AI voice synthesis, character generation, and content manipulation, we‚Äôre approaching a future where derivative works based on original intellectual properties can achieve professional quality while satisfying different interpretations and imaginations. The ‚ÄúYi Tou Jue Lv‚Äù example I mentioned earlier is just the beginning.\nThese perspectives might all exist in the original work, but each remix offers a different angle, providing audiences with unique experiences. There‚Äôs still massive amounts of content that people want to see but isn‚Äôt available on any platform. Maybe creativity‚Äôs next evolution isn‚Äôt about generating entirely new content‚Äîit‚Äôs about intelligently remixing and reinterpreting what already exists to better satisfy what audiences actually want.\nFinal Thoughts While generative AI capabilities evolve rapidly, human nature changes slowly. We overestimate technology‚Äôs short-term creative impact (AI won‚Äôt replace human creativity next year), but underestimate how fundamentally it will change creative workflows (it‚Äôs already happening in ways we‚Äôre only beginning to understand).\nMaking probabilistic models truly creative remains challenging yet fascinating work. The future lies not in AI replacing human creativity, but in building systems that amplify our ability to understand, synthesize, and create meaning from the infinite streams of content around us. That‚Äôs the creative challenge I‚Äôll continue working on.\nAppendix This article was originally developed as a presentation and shared internally with TikTok team members during my time there. The content has been adapted for public publication and adjusted to remove potentially sensitive information while preserving the core insights about AI and creativity.\nAll views expressed in this article are my own and do not represent the official positions or strategies of TikTok or any other organization.\n",
  "wordCount" : "2819",
  "inLanguage": "en",
  "image": "http://localhost:1313/images/profile.jpg","datePublished": "2024-08-25T00:00:00Z",
  "dateModified": "2024-08-25T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Terry Chen"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://localhost:1313/posts/essense_of_creativity/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Terry Chen",
    "logo": {
      "@type": "ImageObject",
      "url": "http://localhost:1313/favicon.ico"
    }
  }
}
</script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-M6GS8Q702L"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'MEASUREMENT_ID');
</script><script type="application/ld+json">
{
  "@context": "https://schema.org",
  
  
  "@type": "BlogPosting",
  
  "headline": "Essence of Creativity: Future of Creative Work",
  "image": "http:\/\/localhost:1313\/",
  "datePublished": "2024-08-25T00:00:00\u002b00:00",
  "dateModified": "2024-08-25T00:00:00\u002b00:00",
  "author": {
    "@type": "Person",
    "name": "Terry Chen"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Terry Chen",
    "logo": {
      "@type": "ImageObject",
      "url": "http:\/\/localhost:1313\/"
    }
  },
  "description": "Exploring the intersection of AI-generated content and human creativity. Analysis of creative workflows, multimodal interactions, and the future of content creation in the AI era.",
  
  "keywords": ["AI creativity", "content generation", "creative workflows", "multimodal AI", "content understanding", "AI-generated content", "creative technology", "content creation"],
  
  
  "wordCount": "2819",
  "timeRequired": "PT14M"
  
}
</script>


 

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position": 1,
      "name": "Home",
      "item": "http:\/\/localhost:1313\/"
    }
    
    ,{
      "@type": "ListItem",
      "position": 2,
      "name": "Posts",
      "item": "http:\/\/localhost:1313\/posts/"
    }
    
    
    ,{
      "@type": "ListItem",
      "position": 3,
      "name": "116",
      "item": "http:\/\/localhost:1313\/categories/116/"
    }
    
    ,{
      "@type": "ListItem",
      "position": 4,
      "name": "Essence of Creativity: Future of Creative Work",
      "item": "http:\/\/localhost:1313\/posts\/essense_of_creativity\/"
    }
  ]
}
</script>
 



<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Person",
  "name": "Terry Chen",
  "url": "http:\/\/localhost:1313\/",
  "sameAs": [
    "https://www.linkedin.com/in/terry-chen-3b44911a4/",
    "https://github.com/terrylinhaochen"
  ],
  "jobTitle": "AI Product Engineer",
  "description": "AI Product Engineer and Investor exploring multi-agent systems, content understanding, and emerging technology investments",
  "knowsAbout": [
    "Artificial Intelligence",
    "Product Engineering", 
    "Investment Analysis",
    "Multi-Agent Systems",
    "Machine Learning",
    "Technology Strategy"
  ],
  "alumniOf": "Northwestern University"
}
</script>



















<style>
   
  link[rel="icon"] {
    content: url("data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üòú</text></svg>");
  }
</style> 
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:1313/" accesskey="h" title="Terry Chen (Alt + H)">Terry Chen</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            
            <li>
                <a href="/posts/" title="Posts">
                    <span class="active">
                        Posts
                    </span>
                </a>
            </li>
            <li>
                <a href="/product/" title="Product">
                    <span>
                        Product
                    </span>
                </a>
            </li>
            <li>
                <a href="/investing/" title="Investing">
                    <span>
                        Investing
                    </span>
                </a>
            </li>
            <li>
                <a href="/search/" title="Explore" accesskey="/">
                    <span>
                        Explore
                    </span>
                </a>
            </li>
            <li>
                <a href="/about/" title="About">
                    <span>
                        About
                    </span>
                </a>
            </li>
        </ul>
    </nav>
</header> <main class="main">
<article class="post-single">
  <header class="post-header">
    <h1 class="post-title">Essence of Creativity: Future of Creative Work</h1>
    
    
    <div class="post-meta">
      By Terry Chen ‚Ä¢ 
      <time>August 25, 2024</time>
    </div>
  </header>
  
  
  <div class="post-content">
    <p>Is it creative to screenshot someone else&rsquo;s video and caption it with other people&rsquo;s comments? This seemingly simple question hits every creator making rent from content: if AI can remix, analyze, and generate at scale, what&rsquo;s left that&rsquo;s genuinely yours?</p>
<p>Through building AI content tools, I&rsquo;ve discovered the real opportunity isn&rsquo;t AI replacing creators‚Äîit&rsquo;s AI helping creators understand the massive amounts of content data around them to find genuinely fresh angles. Think of it as having a research team that can analyze millions of posts, comments, and engagement patterns in seconds, then surface the insights that lead to truly original work.</p>
<div style="text-align: center; margin: 20px 0;">
  <img src="/images/projects/tiktok/tiktok-video-1.png" alt="TikTok Video Interface" style="width: 100%; border-radius: 8px;">
  <p style="font-size: 14px; color: #666; margin-top: 8px;"><em>TikTok's content creation interface: Where creators combine video, audio, and engagement elements to build viral content</em></p>
</div>
<p><em>Note (Nov 4th, 2025): I was actually able to speak to the head of strategy for Mr.Beast and surprisingly enough (or not surprisingly) this is exactly what they are doing and what makes their content so successful - they look for outliers in mass amounts of data - finding videos that genuinely spark viewers&rsquo; interest, even if it&rsquo;s in a different domain - think a Minecraft simulation with 100 players on each island (male/female) and recreating that with actual human participants.</em></p>
<div style="text-align: center; margin: 20px 0;">
  <img src="/images/projects/tiktok/tiktok-video-2.png" alt="TikTok Comment Analysis" style="width: 100%; border-radius: 8px;">
  <p style="font-size: 14px; color: #666; margin-top: 8px;"><em>Comment analytics revealing audience engagement patterns and content resonance across different demographics</em></p>
</div>
<div style="text-align: center; margin: 20px 0;">
  <img src="/images/posts/creativity/content-structure-table.png" alt="Content Component Structure Table" style="width: 100%; border-radius: 8px;">
  <p style="font-size: 14px; color: #666; margin-top: 8px;"><em>Content structure breakdown: How platforms organize multimodal content across video, interaction data, and comments</em></p>
</div>
<p>Let&rsquo;s touch on how, as we can see in this breakdown, what gets abstracted away to just tabular blobs of text contains much information on how information is presented and interacted with. The visual elements and text within the video grab a user&rsquo;s attention, while the audio provides voiceover narrating the message (or sometimes relevant background music). The titles and description provide detailed information on the video, while the comments section‚Äîsomething often overlooked in current processing workflows‚Äîpresents a goldmine of user interaction and feedback.</p>
<p>The primary comments act as tier 1 opinions, with responses and likes serving as interaction trackers. If users have the same opinion, they&rsquo;ll usually hit the like button instead of posting the exact same thing again. By linking the content of the video to actual interactions (both tier 1 and tier 2), we get a polling of audience feedback that is timely and beyond anything we can do in the same amount of time with surveys or really any other kind of data collection.</p>
<p>AI isn&rsquo;t becoming creative‚Äîit&rsquo;s becoming the ultimate creative research assistant. While generative AI struggles to produce truly fresh perspectives, it excels at helping us understand information and generate new insights that lead to genuinely creative work.</p>
<h2 id="what-constitutes-creative-work">What Constitutes Creative Work?</h2>
<p>To understand AI&rsquo;s role in creativity, we need to establish clear boundaries around what constitutes creative work. Consider the common practice of taking screenshots from viral videos and adding captions from popular comments. While this involves some editing, it&rsquo;s essentially sophisticated copying that accelerates content diffusion while reducing the economic returns of original creation‚Äîwhat economist Schumpeter called &ldquo;creative destruction&rdquo; in reverse.</p>
<p>Understanding how platforms structure multimodal content helps us see the complexity involved in creative work.</p>
<p>Real creativity is about choosing a unique perspective. Content with contrast or conflict naturally captures our attention‚Äîthink of viral TikToks that expose workplace absurdities or Twitter threads that challenge conventional wisdom. But thoughtful, empathetic content is equally creative: the YouTube essayist who helps you understand your own anxiety, or the LinkedIn post that perfectly articulates what you&rsquo;ve been feeling about remote work.</p>
<p>Here&rsquo;s how I think about the creative ecosystem: there&rsquo;s production (generating new content) and diffusion (deriving from or spreading existing content). AI&rsquo;s sweet spot isn&rsquo;t in either category alone‚Äîit&rsquo;s in helping us understand massive amounts of information to find genuinely new angles and insights.</p>
<p>Right now, creating professional-quality video requires hours of shooting, editing, and post-production. As AI gets better at handling video, audio, and text together, we&rsquo;re heading toward a world where that same video could be produced in minutes. This changes everything about the creative economy, making tools that help you find new inspiration increasingly valuable. Through this creative assistance, we can achieve two main effects:</p>
<div style="text-align: center; margin: 20px 0;">
  <img src="/images/posts/creativity/creative-assistance-effects.png" alt="Creative Assistance Effects" style="width: 100%; border-radius: 8px;">
  <p style="font-size: 14px; color: #666; margin-top: 8px;"><em>Two primary effects of AI creative assistance: Inspiration acquisition and content derivation</em></p>
</div>
<ol>
<li><strong>Inspiration acquisition</strong>: Accelerating original content production by collapsing the draft ‚Üí iterate loop</li>
<li><strong>Content derivation</strong>: Accelerating the diffusion of quality creative work across formats and channels</li>
</ol>
<h2 id="content-understanding-for-enhanced-generation">Content Understanding for Enhanced Generation</h2>
<p>How can we make language models produce outputs that meet our expectations? This challenge breaks down into two distinct problems: (1) we don&rsquo;t know what our ideal output looks like, and (2) we know what we want, but the language model doesn&rsquo;t understand us.</p>
<p>Most teams focus on the second problem through a toolkit of techniques: model alignment (training AI to follow human preferences), prompting (crafting better instructions), few-shot learning (training AI with just a few examples), retrieval-augmented generation or RAG (helping AI access specific databases), fine-tuning (customizing AI for specific tasks), and memory systems (helping AI remember context across conversations). But companies are rapidly commoditizing these approaches‚Äîmany solutions are open-sourced, which explains why so many generative products deliver roughly comparable results.</p>
<div style="text-align: center; margin: 20px 0;">
  <img src="/images/posts/creativity/ai-workflow-types.png" alt="AI Workflow Types and Capabilities" style="width: 100%; border-radius: 8px;">
  <p style="font-size: 14px; color: #666; margin-top: 8px;"><em>Different types of AI workflows: From basic generation to iterative collaboration</em></p>
</div>
<p>The real differentiation lies in how we adapt engineering and data processing to specific business scenarios‚Äîand more importantly, in solving the first problem: helping users understand what they actually want to create.</p>
<p><em>August 2025: Recently I was asked about what the role of a PM in building technical products stands, especially given how much of the model side work is handled by technical teams. I think the answer, in short, is understanding of the product, and making sense of data in relation to how they are communicated and what they express. One may deal with numbers, but it&rsquo;s harder to actually understand the people that make up those numbers. In the concrete example of multimodal content understanding, it&rsquo;s being able to preserve the very granularity that makes this data so valuable, and proposing technical solutions‚Äîmodality alignment, weighted clustering, agent triage, content rewrite, etc.</em></p>
<h3 id="brand-understanding-and-ai-integration">Brand Understanding and AI Integration</h3>
<div style="text-align: center; margin: 20px 0;">
  <img src="/images/projects/tiktok/tiktok-video-6.png" alt="Brand Intelligence Platform" style="width: 100%; border-radius: 8px;">
  <p style="font-size: 14px; color: #666; margin-top: 8px;"><em>Brand intelligence platform: AI systems learning to understand brand voice, visual identity, and content guidelines for contextual generation</em></p>
</div>
<p>The evolution toward brand-aware AI represents a significant shift in content generation capabilities. Instead of producing generic output that requires extensive human editing, these systems can understand context‚Äîwhat works for a luxury brand versus a startup, what tone resonates with different demographics, what visual styles align with brand guidelines.</p>
<p><em>November 2025: I saw the recent release of Google Pomelli and I think this is a great example of how a general purpose technology moves from research and public beta to a more grounded and applied case that delivers actual time saving and value. Like TypeFace, it&rsquo;s essentially creating a brand kit to free users from prompting repeatedly, and often times not knowing how to most effectively describe their style.</em></p>
<div style="text-align: center; margin: 20px 0;">
  <img src="/images/projects/tiktok/tiktok-video-8.png" alt="AI Brand Training Interface" style="width: 100%; border-radius: 8px;">
  <p style="font-size: 14px; color: #666; margin-top: 8px;"><em>AI brand training interface: How multimodal brand kits teach AI systems to generate content that aligns with specific brand requirements</em></p>
</div>
<p>The training process involves feeding AI systems examples of successful brand content across multiple modalities‚Äîtext, images, videos, and audio. The system learns not just what the brand says, but how it says it, what visual elements it uses, and what emotional tone it maintains. This creates AI that can generate content that feels authentically on-brand without constant human oversight.</p>
<p>Returning to the first problem‚Äî&ldquo;I don&rsquo;t know what output I want&rdquo;‚Äîthis stems from a lack of content understanding. Good script writing requires more than just hooks (&ldquo;You won&rsquo;t believe what happens next&rdquo;), unique selling propositions (USPs), and calls-to-action (CTAs)‚Äîit needs a clear angle: content that resonates with the audience, fits the context, and achieves its purpose.</p>
<p>Some products are building brand kits or audience profiles to guide more specific content generation through manually defined style rules or user personas. While these types of configurations will probably become standard, the real breakthrough would be connecting insight data with generation without requiring manual setup every time.</p>
<h2 id="understanding-user-needs">Understanding User Needs</h2>
<p>Looking at the creative technology landscape, every category‚Äîad aggregation, competitor tracking, brand insights, performance analysis, content generation‚Äîhas 3-4 companies offering basically the same thing. The data products feel traditional, while the AI products often just add ChatGPT integrations to existing workflows.</p>
<p>The real opportunity lies in acquiring more granular data and creating smoother interactions. Instead of isolated tools, imagine connecting the entire creative production process where you can participate and adjust at each stage‚Äîfrom initial research through final publication.</p>
<p>Here&rsquo;s a simple way to think about product value: user value = new experience - old experience - replacement cost. Most products built on foundational language models with minor tweaks deliver limited incremental value. Users still need to craft personalized prompts, and outputs almost always require multiple rounds of editing before they&rsquo;re usable.</p>
<p>So how do we increase incremental value? The answer isn&rsquo;t just better AI‚Äîit&rsquo;s better workflows.</p>
<h2 id="user-friendly-workflows">User-Friendly Workflows</h2>
<p>Currently, creators mostly call upon individual capabilities or data, but single capabilities are insufficient for full-process script/video generation. Building workflows can help users connect various AI capabilities, reducing friction between tool switches.</p>
<p>The concept of &ldquo;workflows, not skills&rdquo; addresses user needs: many users currently need 5-10 AI capabilities to complete their creative work, with most capabilities being disconnected and requiring frequent switching. By establishing a clear workflow, users can more efficiently call upon relevant tools to complete their creative work.</p>
<p>I used to think that simply connecting AI capabilities constitutes a workflow, but that&rsquo;s like saying a toolbox is the same as knowing how to build a house. What we call &ldquo;Language UI&rdquo; is actually &ldquo;Prompt UI&rdquo;‚Äîit differs from true language interaction by missing the context and shared understanding present in human conversation.</p>
<p>Think about the difference: you can tell a colleague &ldquo;make this more engaging&rdquo; and they understand your brand, audience, and context. With ChatGPT, you need to write a novel-length prompt every single time explaining who you are, what you&rsquo;re building, and what &ldquo;engaging&rdquo; means in your specific context.</p>
<p>The future workflow tools will have human-like elements‚Äîthey&rsquo;ll ask follow-up questions, remember previous conversations, and understand your specific goals without you having to explain everything from scratch. Current prompting is probably transitional; eventually, we&rsquo;ll eliminate the need for context-heavy prompts by building AI that understands your context and generates appropriate guidance automatically.</p>
<h2 id="multimodal-interaction-and-content-ecosystem">Multimodal Interaction and Content Ecosystem</h2>
<p>Finally, let&rsquo;s discuss modality. Given the characteristics of different modalities (text - easily editable, images - non-linear, video - linear), different scenarios should use different modalities. The same user may need different interactions in different contexts.</p>
<h3 id="understanding-content-through-data-visualization">Understanding Content Through Data Visualization</h3>
<p>The first layer of multimodal content understanding goes beyond traditional analytics. Rather than just tracking views and likes, the most interesting insights come from clustering comments and opinion spread by category‚Äîproduct feedback, creator engagement, emotional responses. This granular analysis reveals patterns in audience sentiment and helps creators understand not just what performs well, but why it resonates with different audience segments.</p>
<div style="text-align: center; margin: 20px 0;">
  <img src="/images/projects/tiktok/tiktok-video-4.png" alt="Vector Visualization Analysis" style="width: 100%; border-radius: 8px;">
  <p style="font-size: 14px; color: #666; margin-top: 8px;"><em>Vector visualization analysis: AI-powered semantic mapping revealing hidden relationships between content themes and audience preferences</em></p>
</div>
<div style="text-align: center; margin: 20px 0;">
  <img src="/images/projects/tiktok/tiktok-video-3.png" alt="Content Analytics Dashboard" style="width: 100%; border-radius: 8px;">
  <p style="font-size: 14px; color: #666; margin-top: 8px;"><em>Brand intelligence extraction: Analyzing fine-grained insights from audience feedback and engagement patterns</em></p>
</div>
<p>But the real magic happens in semantic analysis. Vector embeddings can reveal hidden relationships between content themes that humans might miss. For example, videos about &ldquo;productivity tips&rdquo; might cluster surprisingly close to &ldquo;cooking tutorials&rdquo; because both satisfy the same underlying need for life optimization. This kind of insight helps creators find unexpected angles and untapped niches.</p>
<div style="text-align: center; margin: 20px 0;">
  <img src="/images/projects/tiktok/tiktok-video-5.png" alt="Content Performance Metrics" style="width: 100%; border-radius: 8px;">
  <p style="font-size: 14px; color: #666; margin-top: 8px;"><em>Content performance metrics: Comprehensive analysis tracking engagement patterns, reach optimization, and conversion effectiveness across content types</em></p>
</div>
<p>The final piece is comprehensive performance analysis that connects creative decisions to business outcomes. This isn&rsquo;t just about vanity metrics‚Äîit&rsquo;s about understanding which content patterns lead to sustainable audience growth, higher conversion rates, and long-term creator success. When you can see these patterns clearly, you can make more informed creative decisions.</p>
<p>Switching between modal forms (long/short/mixed) and modal types (text/image/audio/video) will become easier, essentially providing the same content with applicability across different scenarios. Users aren&rsquo;t just people; they&rsquo;re collections of needs. For instance, I might read text at the office due to setting constraints, watch videos while waiting in line with nothing to do, and listen to audio while driving or commuting. The same content may need three modalities (text/video/audio) connected based on the scenario. This could be further refined - people accelerate reading or listening for higher information intake. Finding ways to adapt the same content to different scenarios without increasing creation costs is another interesting challenge.</p>
<h2 id="case-study-voice-synthesis">Case Study: Voice Synthesis</h2>
<p>Take voice synthesis as an example. Technically, this technology is already quite mature‚Äîyou can clone a voice with just a few minutes of audio. Yet when most people think about AI voice cloning, they imagine phone scams. Sure, there are fun projects like AI David Attenborough narrating random videos, or OpenAI&rsquo;s GPT-4o launch event that briefly simulated Samantha&rsquo;s voice from &ldquo;Her.&rdquo; But the most creative use I&rsquo;ve seen comes from short video creators.</p>
<p>I recently discovered a creator called &ldquo;Yi Tou Jue Lv&rdquo; who makes derivative content based on &ldquo;In the Name of the People&rdquo; (a 2017 Chinese political drama). Their videos consistently get 500K+ views by doing something brilliant: they take original footage but replace all the narration with AI-synthesized character voices speaking internal monologues and psychological commentary. The result feels like getting inside the characters&rsquo; heads in a way the original show never offered.</p>
<p>What makes this work is the creator&rsquo;s deep understanding of the characters combined with AI&rsquo;s ability to generate consistent, high-quality voice synthesis. They&rsquo;re not just copying‚Äîthey&rsquo;re creating a completely new layer of interpretation that audiences can&rsquo;t get anywhere else.</p>
<h2 id="contrasting-audio--text">Contrasting Audio &amp; Text</h2>
<p>It&rsquo;s fascinating how differently our brains process audio and text. When we read, we&rsquo;re essentially interacting with a graphical user interface‚Äîscanning, jumping between sections, processing information at our own pace. We&rsquo;ve evolved sophisticated tools for text: highlighting, bookmarking, section headers, and search functions. Yet despite these advantages, text can feel less engaging than a good conversation.</p>
<div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 20px 0;">
  <img src="/images/posts/creativity/podcast-interface.png" alt="Podcast Interface" style="width: 100%; border-radius: 8px;">
  <img src="/images/posts/creativity/wechat-saved-audio.png" alt="WeChat Audio Saving Interface" style="width: 100%; border-radius: 8px;">
</div>
<p style="font-size: 14px; color: #666; text-align: center; margin-top: 8px;"><em>Audio interfaces evolution: From podcast consumption (left) to social audio saving (right)‚Äîplatforms adapting to our increasingly audio-first content behaviors and the need to preserve valuable conversations</em></p>
<p>Speaking, in contrast, is inherently linear and social. There&rsquo;s something about the human voice that keeps us present‚Äîthe subtle shifts in tone, the natural pauses, the back-and-forth rhythm. It&rsquo;s why we can stay engaged in a podcast while walking (and multitask), yet reading typically demands our full attention.</p>
<p>This contrast reveals something deeper about how we process information. Text excels at conveying complex ideas‚Äîwe can revisit difficult passages, cross-reference concepts, and process at our own speed. Audio shines in maintaining engagement and conveying emotion, even if the content itself is relatively simple. Perhaps the future lies not in choosing between these mediums, but in finding ways to combine their strengths. Imagine an interface that preserves the natural flow of conversation while adding the structural advantages of text‚Äîwhere you could navigate both temporally and conceptually, maintaining both engagement and comprehension.</p>
<h2 id="conclusion">Conclusion</h2>
<div style="text-align: center; margin: 20px 0;">
  <img src="/images/posts/creativity/death-of-author.png" alt="Death of the Author by Roland Barthes" style="width: 100%; border-radius: 8px;">
  <p style="font-size: 14px; color: #666; margin-top: 8px;"><em>Roland Barthes' "Death of the Author": When content is created, interpretation rights transfer to the audience</em></p>
</div>
<p>As Roland Barthes suggested with &ldquo;The Death of the Author,&rdquo; once content is created, interpretation rights transfer to the audience. We see this everywhere today‚ÄîYouTube channels that analyze every Marvel movie, TikTok accounts that remix old TV shows, podcast networks that dissect every episode of popular series.</p>
<p>With improvements in AI voice synthesis, character generation, and content manipulation, we&rsquo;re approaching a future where derivative works based on original intellectual properties can achieve professional quality while satisfying different interpretations and imaginations. The &ldquo;Yi Tou Jue Lv&rdquo; example I mentioned earlier is just the beginning.</p>
<p>These perspectives might all exist in the original work, but each remix offers a different angle, providing audiences with unique experiences. There&rsquo;s still massive amounts of content that people want to see but isn&rsquo;t available on any platform. Maybe creativity&rsquo;s next evolution isn&rsquo;t about generating entirely new content‚Äîit&rsquo;s about intelligently remixing and reinterpreting what already exists to better satisfy what audiences actually want.</p>
<h2 id="final-thoughts">Final Thoughts</h2>
<p>While generative AI capabilities evolve rapidly, human nature changes slowly. We overestimate technology&rsquo;s short-term creative impact (AI won&rsquo;t replace human creativity next year), but underestimate how fundamentally it will change creative workflows (it&rsquo;s already happening in ways we&rsquo;re only beginning to understand).</p>
<p>Making probabilistic models truly creative remains challenging yet fascinating work. The future lies not in AI replacing human creativity, but in building systems that amplify our ability to understand, synthesize, and create meaning from the infinite streams of content around us. That&rsquo;s the creative challenge I&rsquo;ll continue working on.</p>
<hr>
<h2 id="appendix">Appendix</h2>
<p>This article was originally developed as a presentation and shared internally with TikTok team members during my time there. The content has been adapted for public publication and adjusted to remove potentially sensitive information while preserving the core insights about AI and creativity.</p>
<p>All views expressed in this article are my own and do not represent the official positions or strategies of TikTok or any other organization.</p>

  </div>
  
  
  
  <footer class="post-footer">
    <div class="post-tags">
      
      <a href="/tags/observations">Observations</a>
      
      <a href="/tags/entrepreneurship">Entrepreneurship</a>
      
      <a href="/tags/product">Product</a>
      
      <a href="/tags/posts">Posts</a>
      
    </div>
  </footer>
  

  
  

  
  
</article>




<div class="related-posts">
  <h3>Related Articles</h3>
  <div class="related-posts-grid">
    
    <a href="/archived/cogno/" class="related-post-card">
      <div class="related-post-content">
        <h4>Cogno: Multi-agent AI for Sales Automation</h4>
        <div class="related-post-meta">
          <span class="related-post-date">March 1, 2024</span>
          
          <span class="related-post-tags">
            #Entrepreneurship
          </span>
          
        </div>
        <p class="related-post-excerpt">Multi-agent system for cross boarder e-commerce sales automation. Co-founder and head of product. ‚Ä¶</p>
      </div>
    </a>
    
    <a href="/posts/llmcoaching/" class="related-post-card">
      <div class="related-post-content">
        <h4>Building AI That Actually Understands How Students Learn</h4>
        <div class="related-post-meta">
          <span class="related-post-date">August 15, 2024</span>
          
          <span class="related-post-tags">
            #Product
          </span>
          
        </div>
        <p class="related-post-excerpt">Terry Chen, Allyson Lee
Your engineering team is stuck. Again.
It&rsquo;s not that they lack the ‚Ä¶</p>
      </div>
    </a>
    
    <a href="/posts/copilot/" class="related-post-card">
      <div class="related-post-content">
        <h4>Multi-modal Creative Ad Generation</h4>
        <div class="related-post-meta">
          <span class="related-post-date">May 20, 2024</span>
          
          <span class="related-post-tags">
            #Product
          </span>
          
        </div>
        <p class="related-post-excerpt">The advertising industry&rsquo;s AI tools problem isn&rsquo;t about generation quality‚Äîit&rsquo;s ‚Ä¶</p>
      </div>
    </a>
    
    <a href="/archived/marrrket/" class="related-post-card">
      <div class="related-post-content">
        <h4>Marrrket: AI Listing Secondhand Marketplace</h4>
        <div class="related-post-meta">
          <span class="related-post-date">March 20, 2024</span>
          
          <span class="related-post-tags">
            #Product
          </span>
          
        </div>
        <p class="related-post-excerpt">Marrrket is an AI-powered second-hand marketplace platform targeting North American university ‚Ä¶</p>
      </div>
    </a>
    
  </div>
</div>

<style>
  .related-posts {
    margin-top: 3rem;
    padding-top: 2rem;
    border-top: 1px solid var(--border);
    max-width: var(--content-width, 720px);
    margin-left: auto;
    margin-right: auto;
    width: 100%;
    padding-left: var(--gap);
    padding-right: var(--gap);
  }
  
  .related-posts h3 {
    margin-bottom: 1.5rem;
    font-size: 1.5rem;
    font-weight: 600;
    color: var(--primary);
  }
  
  .related-posts-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
    gap: 1.5rem;
  }
  
  .related-post-card {
    display: block;
    padding: 1.2rem;
    border-radius: var(--radius);
    background: var(--code-bg);
    border: 1px solid var(--border);
    box-shadow: var(--shadow);
    transition: transform 0.2s, box-shadow 0.2s;
    text-decoration: none;
  }
  
  .related-post-card:hover {
    transform: translateY(-3px);
    box-shadow: 0 5px 15px rgba(0,0,0,0.1);
  }
  
  :root[data-theme="dark"] .related-post-card:hover {
    box-shadow: 0 5px 15px rgba(0,0,0,0.4);
  }
  
  .related-post-card h4 {
    margin: 0 0 0.6rem 0;
    font-size: 1.1rem;
    font-weight: 500;
    color: var(--primary);
    line-height: 1.3;
  }
  
  .related-post-meta {
    display: flex;
    justify-content: space-between;
    margin-bottom: 0.8rem;
    font-size: 0.85rem;
    color: var(--secondary);
  }
  
  .related-post-excerpt {
    font-size: 0.95rem;
    color: var(--content);
    line-height: 1.5;
    margin: 0;
  }
  
  @media (max-width: 768px) {
    .related-posts-grid {
      grid-template-columns: 1fr;
    }
  }
</style>
 


<style>
   
  body {
    background-color: var(--theme);
  }
  
  .post-single {
    background-color: var(--entry);
    border-radius: var(--radius);
     
    max-width: var(--content-width, 720px);
    width: 100%;
    margin-left: auto;
    margin-right: auto;
    padding: var(--gap);
    margin-bottom: var(--gap);
    box-shadow: var(--shadow);
  }
  
  .post-content {
    margin-top: var(--content-gap);
    color: var(--content);
  }
  
  .post-content h1,
  .post-content h2,
  .post-content h3,
  .post-content h4 {
    margin: 1.5em 0 0.5em;
    color: var(--primary);
  }

   
  .version-history {
    margin-top: 2rem;
    padding: 1.5rem;
    background-color: var(--code-bg);
    border-radius: var(--radius);
    border-left: 4px solid var(--primary);
  }

  .version-history h3 {
    margin: 0 0 1rem 0;
    color: var(--primary);
    font-size: 1.1rem;
  }

  .version-item {
    margin-bottom: 1rem;
    padding-bottom: 0.75rem;
    border-bottom: 1px solid var(--border);
  }

  .version-item:last-child {
    border-bottom: none;
    margin-bottom: 0;
  }

  .version-header {
    display: flex;
    align-items: center;
    gap: 0.75rem;
    margin-bottom: 0.25rem;
    flex-wrap: wrap;
  }

  .version-number {
    font-weight: bold;
    color: var(--primary);
    font-family: var(--font-mono, monospace);
  }

  .version-date {
    color: var(--secondary);
    font-size: 0.9rem;
  }

  .current-badge {
    background-color: var(--primary);
    color: var(--theme);
    padding: 0.2rem 0.5rem;
    border-radius: 0.25rem;
    font-size: 0.8rem;
    font-weight: bold;
  }

  .view-commits {
    color: var(--primary);
    text-decoration: none;
    font-size: 0.9rem;
    padding: 0.2rem 0.5rem;
    border: 1px solid var(--primary);
    border-radius: 0.25rem;
    transition: all 0.2s ease;
    display: inline-flex;
    align-items: center;
    gap: 0.25rem;
  }

  .view-commits:hover {
    background-color: var(--primary);
    color: var(--theme);
  }

  .view-commits svg {
    width: 14px;
    height: 14px;
  }

  .git-info {
    margin-top: 1rem;
    text-align: center;
    color: var(--secondary);
    font-style: italic;
  }

  .version-changes {
    color: var(--content);
    font-style: italic;
    margin-bottom: 0.25rem;
    font-size: 0.95rem;
  }

  .version-summary {
    color: var(--secondary);
    font-size: 0.9rem;
  }

  .update-info {
    margin-top: 1rem;
    text-align: center;
    color: var(--secondary);
    border-top: 1px solid var(--border);
    padding-top: 1rem;
  }
</style>

    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:1313/">Terry Chen</a></span> ¬∑ 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
    
    
    <div class="archived-link">
        <span style="font-size: 0.85em; color: #888; margin-top: 8px; display: block;">
            To view archived content, <a href="/archived/" style="color: #666; text-decoration: underline;">click here</a>
        </span>
    </div>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>



<div id="subscribe-system">
  
  <div id="subscription-modal" class="subscription-modal hidden">
    <div class="modal-overlay"></div>
    <div class="modal-content">
      <button id="modal-close" class="modal-close" title="Close">√ó</button>
      <div class="modal-body">
        <h2>Stay close to the frontier</h2>
        <p>Get updates when I publish new insights about design, technology, and human interaction patterns.</p>
        <form id="subscription-form" class="centered-subscribe-form">
          <input type="email" id="subscription-email" placeholder="your@email.com" required>
          <button type="submit" class="submit-btn">Subscribe</button>
        </form>
        <div id="subscription-message" class="form-message"></div>
        <div class="modal-footer">
          <button id="modal-no-thanks" class="no-thanks-btn">No thanks</button>
        </div>
      </div>
    </div>
  </div>

  
  <div id="user-reminder" class="returning-reminder hidden">
    
    <div id="reminder-collapsed" class="reminder-collapsed clickable">
      <span class="reminder-text">Explore More Content</span>
      <div class="expand-btn">
        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
          <path d="m18 15-6-6-6 6"/>
        </svg>
      </div>
    </div>
    
    
    <div id="reminder-expanded" class="reminder-expanded hidden">
      <div class="expanded-header">
        <h4>Stay close to the frontier</h4>
        <button id="reminder-close" class="reminder-close" title="Minimize">
          <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2">
            <path d="M6 9l6 6 6-6"/>
          </svg>
        </button>
      </div>
      <p>Get updates when I publish new insights about design, technology, and human interaction patterns.</p>
      
      <div class="action-options">
        <a href="/posts/" class="action-item">
          <div class="action-icon">üìñ</div>
          <span class="action-text">Read an article</span>
          <div class="action-arrow">‚Ä∫</div>
        </a>
        
        <a href="https://crowdlisten.com" target="_blank" class="action-item">
          <div class="action-icon">üë•</div>
          <span class="action-text">Understand users with Crowdlisten</span>
          <div class="action-arrow">‚Ä∫</div>
        </a>
        
        <div class="action-item subscribe-item">
          <div class="action-icon">‚úâÔ∏è</div>
          <span class="action-text">Subscribe for updates</span>
          <div class="action-arrow">‚Ä∫</div>
        </div>
      </div>
    </div>
  </div>
</div>

<script>
class SimplifiedSubscribe {
  constructor() {
    this.init();
  }

  init() {
    this.setupEventListeners();
    
    
    if (this.isNewVisitor()) {
      setTimeout(() => this.showCenteredModal(), 1000); 
    }
    
    
    this.showUserReminder();
  }

  
  isNewVisitor() {
    const hasVisited = localStorage.getItem('has-visited');
    if (!hasVisited && !this.hasSubscribed()) {
      localStorage.setItem('has-visited', 'true');
      return true;
    }
    return false;
  }

  
  hasSubscribed() {
    return localStorage.getItem('newsletter-subscribed') === 'true';
  }

  hasPermanentlyDismissed() {
    return localStorage.getItem('newsletter-never-show') === 'true';
  }

  
  showUserReminder() {
    document.getElementById('user-reminder').classList.remove('hidden');
  }

  hideUserReminder() {
    document.getElementById('user-reminder').classList.add('hidden');
  }

  
  expandReminder() {
    document.getElementById('reminder-collapsed').classList.add('hidden');
    document.getElementById('reminder-expanded').classList.remove('hidden');
  }

  collapseReminder() {
    const expanded = document.getElementById('reminder-expanded');
    const collapsed = document.getElementById('reminder-collapsed');
    
    
    expanded.style.animation = 'collapseVertical 0.2s ease-in forwards';
    
    setTimeout(() => {
      expanded.classList.add('hidden');
      expanded.style.animation = '';
      collapsed.classList.remove('hidden');
    }, 200);
  }

  
  showCenteredModal() {
    document.getElementById('subscription-modal').classList.remove('hidden');
  }

  
  hideCenteredModal() {
    document.getElementById('subscription-modal').classList.add('hidden');
  }

  
  async submitSubscription(email, source) {
    try {
      const pageUrl = window.location.href;
      
      const response = await fetch('https://script.google.com/macros/s/AKfycbxF7czbmo2JEeATzFoMnHIfGASoSTzogbjJcuQm30sjBXFqmDOqISWkIHBr64GdmURS/exec', {
        method: 'POST',
        mode: 'no-cors',
        headers: {
          'Content-Type': 'application/x-www-form-urlencoded',
        },
        body: new URLSearchParams({
          'email': email,
          'pageUrl': pageUrl,
          'source': source
        })
      });

      
      localStorage.setItem('newsletter-subscribed', 'true');
      
      
      setTimeout(() => {
        this.resetToActionOptions();
      }, 2000);

      return true;
    } catch (error) {
      console.error('Subscription error:', error);
      return false;
    }
  }

  
  resetToActionOptions() {
    this.hideCenteredModal();
    
    document.getElementById('subscription-email').value = '';
    document.getElementById('subscription-message').textContent = '';
    document.getElementById('subscription-message').classList.remove('success', 'error');
  }

  
  setupEventListeners() {
    
    document.getElementById('reminder-collapsed')?.addEventListener('click', () => {
      this.expandReminder();
    });

    document.getElementById('reminder-close')?.addEventListener('click', () => {
      this.collapseReminder();
    });

    
    document.querySelector('.subscribe-item')?.addEventListener('click', () => {
      this.showCenteredModal();
    });

    document.getElementById('user-form')?.addEventListener('submit', async (e) => {
      e.preventDefault();
      const email = document.getElementById('user-email').value;
      const messageEl = document.getElementById('user-message');
      const submitBtn = e.target.querySelector('button[type="submit"]');
      
      submitBtn.disabled = true;
      submitBtn.textContent = 'Subscribing...';
      
      const success = await this.submitSubscription(email, 'user-reminder');
      
      if (success) {
        messageEl.textContent = 'Thanks for subscribing!';
        messageEl.classList.add('success');
        setTimeout(() => this.hideUserReminder(), 2000);
      } else {
        messageEl.textContent = 'Something went wrong. Please try again.';
        messageEl.classList.add('error');
      }
      
      submitBtn.disabled = false;
      submitBtn.textContent = 'Subscribe';
    });


    
    document.getElementById('modal-close')?.addEventListener('click', () => {
      this.hideCenteredModal();
    });

    document.querySelector('.modal-overlay')?.addEventListener('click', () => {
      this.hideCenteredModal();
    });

    document.getElementById('subscription-form')?.addEventListener('submit', async (e) => {
      e.preventDefault();
      const email = document.getElementById('subscription-email').value;
      const messageEl = document.getElementById('subscription-message');
      const submitBtn = e.target.querySelector('button[type="submit"]');
      
      submitBtn.disabled = true;
      submitBtn.textContent = 'Subscribing...';
      
      const success = await this.submitSubscription(email, 'centered-modal');
      
      if (success) {
        messageEl.textContent = 'Thanks for subscribing!';
        messageEl.classList.add('success');
        setTimeout(() => this.hideCenteredModal(), 2000);
      } else {
        messageEl.textContent = 'Something went wrong. Please try again.';
        messageEl.classList.add('error');
      }
      
      submitBtn.disabled = false;
      submitBtn.textContent = 'Subscribe';
    });

    document.getElementById('modal-no-thanks')?.addEventListener('click', () => {
      this.hideCenteredModal();
    });
  }
}


document.addEventListener('DOMContentLoaded', () => {
  new SimplifiedSubscribe();
});
</script>

<style>
 
.hidden {
  display: none !important;
}

 
.subscription-modal {
  position: fixed;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  z-index: 9999;
  display: flex;
  align-items: center;
  justify-content: center;
  animation: fadeIn 0.4s ease-out;
}

.modal-overlay {
  position: absolute;
  top: 0;
  left: 0;
  right: 0;
  bottom: 0;
  background: rgba(0,0,0,0.8);
  backdrop-filter: blur(4px);
}

.subscription-modal .modal-content {
  position: relative;
  background: var(--entry);
  border: 1px solid var(--border);
  border-radius: var(--radius);
  max-width: 680px;
  width: 95%;
  max-height: 90vh;
  overflow-y: auto;
  box-shadow: var(--shadow);
  animation: modalSlideIn 0.5s ease-out;
  font-family: inherit;
}

.modal-close {
  position: absolute;
  top: 20px;
  right: 20px;
  background: none;
  border: none;
  font-size: 24px;
  cursor: pointer;
  color: var(--secondary);
  padding: 8px;
  border-radius: var(--radius);
  transition: all 0.2s ease;
  opacity: 0.6;
}

.modal-close:hover {
  opacity: 1;
  background: var(--theme);
  color: var(--primary);
}

.modal-body {
  padding: calc(var(--gap) * 2);
  text-align: center;
}

.modal-body h2 {
  margin: 0 0 24px 0;
  font-size: 32px;
  font-weight: 700;
  color: var(--primary);
  font-family: inherit;
  line-height: 1.2;
}

.modal-body p {
  margin: 0 0 32px 0;
  color: var(--secondary);
  line-height: 1.6;
  font-size: 16px;
  font-family: inherit;
  max-width: 480px;
  margin-left: auto;
  margin-right: auto;
}

 
.centered-subscribe-form {
  display: flex;
  flex-direction: column;
  gap: 16px;
  margin-bottom: 24px;
  max-width: 400px;
  margin-left: auto;
  margin-right: auto;
}

.centered-subscribe-form input {
  padding: 16px 20px;
  border: 1px solid var(--border);
  border-radius: var(--radius);
  font-size: 16px;
  background: var(--theme);
  color: var(--primary);
  font-family: inherit;
  transition: border-color 0.2s ease;
  text-align: center;
}

.centered-subscribe-form input::placeholder {
  color: var(--secondary);
  opacity: 0.7;
}

.centered-subscribe-form input:focus {
  outline: none;
  border-color: var(--primary);
}

.centered-subscribe-form .submit-btn {
  background: var(--primary);
  color: var(--theme);
  border: none;
  padding: 16px 24px;
  border-radius: var(--radius);
  font-size: 16px;
  font-weight: 600;
  cursor: pointer;
  transition: all 0.2s ease;
  font-family: inherit;
}

.centered-subscribe-form .submit-btn:hover {
  opacity: 0.9;
  transform: translateY(-1px);
}

.centered-subscribe-form .submit-btn:disabled {
  opacity: 0.6;
  transform: none;
  cursor: not-allowed;
}

.modal-footer {
  text-align: center;
  margin-top: 16px;
}

 

 
.subscribe-form {
  display: flex;
  flex-direction: column;
  gap: 12px;
  margin-bottom: 16px;
  width: 100%;
}

.subscribe-form input {
  padding: 14px 16px;
  border: 1px solid var(--border);
  border-radius: var(--radius);
  font-size: 14px;
  background: var(--theme);
  color: var(--primary);
  font-family: inherit;
  transition: border-color 0.2s ease;
  box-sizing: border-box;
  width: 100%;
  text-align: left;
}

.subscribe-form input::placeholder {
  color: var(--secondary);
  opacity: 0.7;
}

.subscribe-form input:focus {
  outline: none;
  border-color: var(--primary);
}

.submit-btn {
  background: var(--primary);
  color: var(--theme);
  border: none;
  padding: 14px 16px;
  border-radius: var(--radius);
  font-size: 14px;
  font-weight: 600;
  cursor: pointer;
  transition: all 0.2s ease;
  font-family: inherit;
  box-sizing: border-box;
  width: 100%;
}

.no-thanks-btn {
  background: none;
  border: none;
  color: var(--secondary);
  font-size: 14px;
  cursor: pointer;
  text-decoration: underline;
  font-family: inherit;
  transition: color 0.2s ease;
  opacity: 0.8;
}

.no-thanks-btn:hover {
  color: var(--primary);
  opacity: 1;
}

 
.returning-reminder {
  position: fixed;
  bottom: 0;
  right: 0;
  z-index: 999;
  font-family: inherit;
}

 
.reminder-collapsed {
  background: var(--entry);
  border: 1px solid var(--border);
  border-radius: calc(var(--radius) * 2) calc(var(--radius) * 2) 0 0;
  padding: 12px 20px;
  box-shadow: var(--shadow);
  display: flex;
  align-items: center;
  justify-content: space-between;
  cursor: pointer;
  transition: all 0.3s ease;
  user-select: none;
  width: 360px;
  margin: 0;
}

.reminder-collapsed.clickable {
  cursor: pointer;
}

.reminder-collapsed:hover {
  transform: translateY(-2px);
  box-shadow: 0 4px 16px rgba(0,0,0,0.15);
}

.reminder-text {
  font-size: 14px;
  color: var(--secondary);
  font-weight: 500;
  white-space: nowrap;
}

.expand-btn {
  background: var(--theme);
  border: 1px solid var(--border);
  border-radius: 50%;
  padding: 6px;
  transition: all 0.2s ease;
  display: flex;
  align-items: center;
  justify-content: center;
  color: var(--secondary);
  pointer-events: none;
}

.reminder-collapsed:hover .expand-btn {
  background: var(--border);
  color: var(--primary);
}

 
.reminder-expanded {
  background: var(--entry);
  border: 1px solid var(--border);
  border-radius: var(--radius) var(--radius) 0 0;
  padding: 24px;
  box-shadow: var(--shadow);
  width: 360px;
  animation: expandVertical 0.3s ease-out;
  margin: 0;
  box-sizing: border-box;
}

.expanded-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 16px;
}

.expanded-header h4 {
  margin: 0;
  font-size: 18px;
  font-weight: 600;
  color: var(--primary);
  font-family: inherit;
}

.reminder-close {
  background: none;
  border: none;
  cursor: pointer;
  color: var(--secondary);
  padding: 4px;
  transition: all 0.2s ease;
  border-radius: 4px;
  display: flex;
  align-items: center;
  justify-content: center;
}

.reminder-close:hover {
  color: var(--primary);
  background: var(--theme);
}

.reminder-expanded p {
  margin: 0 0 20px 0;
  font-size: 14px;
  color: var(--secondary);
  line-height: 1.6;
  font-family: inherit;
}

 
.action-options {
  display: flex;
  flex-direction: column;
  gap: 8px;
  margin-bottom: 16px;
}

.action-item {
  display: flex;
  align-items: center;
  padding: 12px 16px;
  border: 1px solid var(--border);
  border-radius: var(--radius);
  background: var(--theme);
  color: var(--primary);
  text-decoration: none;
  transition: all 0.2s ease;
  cursor: pointer;
}

.action-item:hover {
  background: var(--code-bg);
  border-color: var(--primary);
}

.action-icon {
  font-size: 16px;
  margin-right: 12px;
  min-width: 20px;
}

.action-text {
  flex: 1;
  font-size: 14px;
  font-weight: 500;
}

.action-arrow {
  font-size: 18px;
  color: var(--secondary);
  margin-left: 8px;
}

.action-item:hover .action-arrow {
  color: var(--primary);
}

.reminder-actions {
  text-align: center;
  margin-top: 16px;
}

 
.form-message {
  margin-top: 16px;
  padding: 12px 16px;
  border-radius: var(--radius);
  font-size: 14px;
  text-align: center;
  font-family: inherit;
}

.form-message.success {
  background: var(--code-bg);
  color: var(--primary);
  border: 1px solid var(--border);
}

.form-message.error {
  background: var(--code-bg);
  color: var(--primary);
  border: 1px solid var(--border);
}

 
@keyframes fadeIn {
  from {
    opacity: 0;
  }
  to {
    opacity: 1;
  }
}

@keyframes modalSlideIn {
  from {
    transform: scale(0.95) translateY(-10px);
    opacity: 0;
  }
  to {
    transform: scale(1) translateY(0);
    opacity: 1;
  }
}

@keyframes expandVertical {
  from {
    transform: scaleY(0);
    transform-origin: bottom;
    opacity: 0;
  }
  to {
    transform: scaleY(1);
    transform-origin: bottom;
    opacity: 1;
  }
}

@keyframes collapseVertical {
  from {
    transform: scaleY(1);
    transform-origin: bottom;
    opacity: 1;
  }
  to {
    transform: scaleY(0);
    transform-origin: bottom;
    opacity: 0;
  }
}

 
@media (max-width: 768px) {
  .new-user-modal .modal-content {
    margin: 20px;
    width: calc(100% - 40px);
  }
  
  .modal-body {
    padding: var(--gap);
  }
  
  .modal-body h2 {
    font-size: 28px;
  }
  
  .returning-reminder {
    right: 0;
    bottom: 0;
  }
  
  .reminder-expanded {
    width: 100vw;
    max-width: 360px;
    padding: 16px;
  }
  
  .reminder-collapsed {
    padding: 10px 16px;
    width: 100vw;
    max-width: 360px;
  }
  
  .reminder-text {
    font-size: 13px;
  }
}

 
:root {
  --main-width: 720px;
  --gap: 24px;
  --radius: 8px;
  --shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
}
</style>

<script>
    
    window.addEventListener('error', function(e) {
        console.error('Page error:', e.error);
        console.error('Error details:', {
            message: e.message,
            filename: e.filename,
            lineno: e.lineno,
            colno: e.colno
        });
    });

    
    if (history.scrollRestoration) {
        history.scrollRestoration = 'manual';
    }
    
    
    window.addEventListener('load', function() {
        window.scrollTo(0, 0);
    });
    
    
    window.addEventListener('pageshow', function(event) {
        if (event.persisted) {
            window.scrollTo(0, 0);
        }
    });

    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script> </body>

</html>
