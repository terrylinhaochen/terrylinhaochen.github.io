<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/"><channel><title>Research - Terry Chen</title><link>https://chenterry.com/tags/research/</link><description>Hi, this is Terry. I'm documenting my product ideas and learning notes in this blog. I'm interested in creating new user experiences through generative ai, focusing on synthesized content generation and actionable insight extraction.</description><language>en-us</language><managingEditor>Terry Chen (Terry Chen)</managingEditor><webMaster>Terry Chen (Terry Chen)</webMaster><copyright>© 2025 Terry Chen. All rights reserved.</copyright><lastBuildDate>Mon, 10 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://chenterry.com/tags/research/index.xml" rel="self" type="application/rss+xml"/><generator>Hugo 0.136.2</generator><category>Technology</category><category>AI</category><category>Product Engineering</category><category>Investment Analysis</category><image><url>https://chenterry.com/images/profile.jpg</url><title>Terry Chen</title><link>https://chenterry.com/</link><description>Hi, this is Terry. I'm documenting my product ideas and learning notes in this blog. I'm interested in creating new user experiences through generative ai, focusing on synthesized content generation and actionable insight extraction.</description><width>144</width><height>144</height></image><item><title>LLM Memory Consolidation and Augmentation</title><link>https://chenterry.com/archived/human-inspired-llm-memory/</link><pubDate>Mon, 10 Mar 2025 00:00:00 +0000</pubDate><author>Terry Chen (Terry Chen)</author><guid>https://chenterry.com/archived/human-inspired-llm-memory/</guid><description>&lt;p>&lt;strong>Authors: Terry Chen, Kaiwen Che, Matthew Song&lt;/strong>&lt;/p>
&lt;h2 id="abstract">Abstract&lt;/h2>
&lt;p>Despite advances in large language model (LLM) capability, their fundamental limitation of not being able to store context over long-lived interactions persists. In this paper, a novel human-inspired three-tiered memory architecture is presented that addresses these limitations through biomimetic design principles rooted in cognitive science. Our approach aligns the human working memory with the LLM context window, episodic memory with vector stores of experience-based knowledge, and semantic memory with structured knowledge triplets.&lt;/p></description><category>research</category><category>Research</category><dc:creator>Terry Chen</dc:creator><dc:date>2025-03-10T00:00:00Z</dc:date></item><item><title>Realtime Conversational Learning Aid</title><link>https://chenterry.com/archived/groupal/</link><pubDate>Sun, 10 Nov 2024 00:00:00 +0000</pubDate><author>Terry Chen (Terry Chen)</author><guid>https://chenterry.com/archived/groupal/</guid><description>AI-powered study group assistant that analyzes real-time conversations, detects misconceptions, and facilitates deeper learning through Socratic questioning and contextual knowledge retrieval.</description><category>research</category><category>Research</category><dc:creator>Terry Chen</dc:creator><dc:date>2024-11-10T00:00:00Z</dc:date></item><item><title>Building AI That Actually Understands How Students Learn</title><link>https://chenterry.com/posts/llmcoaching/</link><pubDate>Thu, 15 Aug 2024 00:00:00 +0000</pubDate><author>Terry Chen (Terry Chen)</author><guid>https://chenterry.com/posts/llmcoaching/</guid><description>How we built an LLM system that identifies student learning gaps and connects them with peers who've solved similar problems—scaling personalized mentorship through AI that understands the nuances of how people actually learn.</description><category>northwestern</category><category>Product</category><category>Research</category><dc:creator>Terry Chen</dc:creator><dc:date>2024-08-15T00:00:00Z</dc:date></item></channel></rss>